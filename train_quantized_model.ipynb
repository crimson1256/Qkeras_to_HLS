{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a1411cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 18:35:44.802274: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-02 18:35:44.802310: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed)\n",
    "import os\n",
    "os.environ['PATH'] = '/opt/Xilinx/Vivado/2019.2/bin:' + os.environ['PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a7efbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_em_barrel = np.load('x_test_em_barrel.npy')\n",
    "x_train_em_barrel = np.load('x_train_em_barrel.npy')\n",
    "y_train_targets = np.load('y_train_targets.npy')\n",
    "y_test_targets = np.load('y_test_targets.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47ccf839",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam, Nadam\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from callbacks import all_callbacks\n",
    "from tensorflow.keras.layers import Activation\n",
    "from qkeras.qlayers import QDense, QActivation\n",
    "from qkeras.quantizers import quantized_bits, quantized_relu\n",
    "from qkeras import QActivation\n",
    "from qkeras import QDense, QConv2DBatchnorm\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cc172c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4611673a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "em_barrel (InputLayer)       [(None, 56, 11, 4)]       0         \n",
      "_________________________________________________________________\n",
      "up_sampling (UpSampling2D)   (None, 56, 55, 4)         0         \n",
      "_________________________________________________________________\n",
      "batch_norm (BatchNormalizati (None, 56, 55, 4)         16        \n",
      "_________________________________________________________________\n",
      "conv (Conv2D)                (None, 56, 55, 16)        1600      \n",
      "_________________________________________________________________\n",
      "batch_norm_1 (BatchNormaliza (None, 56, 55, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_relu (LeakyReLU)       (None, 56, 55, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2D (MaxPooling2D) (None, 28, 27, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv_1 (Conv2D)              (None, 28, 27, 32)        4608      \n",
      "_________________________________________________________________\n",
      "batch_norm_2 (BatchNormaliza (None, 28, 27, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_relu_1 (LeakyReLU)     (None, 28, 27, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv2D)              (None, 28, 27, 32)        9216      \n",
      "_________________________________________________________________\n",
      "batch_norm_3 (BatchNormaliza (None, 28, 27, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_relu_2 (LeakyReLU)     (None, 28, 27, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2D_1 (MaxPooling2 (None, 14, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_3 (Conv2D)              (None, 14, 13, 64)        18432     \n",
      "_________________________________________________________________\n",
      "batch_norm_4 (BatchNormaliza (None, 14, 13, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_relu_3 (LeakyReLU)     (None, 14, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_4 (Conv2D)              (None, 14, 13, 64)        36864     \n",
      "_________________________________________________________________\n",
      "batch_norm_5 (BatchNormaliza (None, 14, 13, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_relu_4 (LeakyReLU)     (None, 14, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2D_2 (MaxPooling2 (None, 7, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv_5 (Conv2D)              (None, 7, 6, 128)         73728     \n",
      "_________________________________________________________________\n",
      "batch_norm_6 (BatchNormaliza (None, 7, 6, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_relu_5 (LeakyReLU)     (None, 7, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv_6 (Conv2D)              (None, 7, 6, 128)         147456    \n",
      "_________________________________________________________________\n",
      "batch_norm_7 (BatchNormaliza (None, 7, 6, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_relu_6 (LeakyReLU)     (None, 7, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2D_3 (MaxPooling2 (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv_7 (Conv2D)              (None, 3, 3, 256)         294912    \n",
      "_________________________________________________________________\n",
      "batch_norm_8 (BatchNormaliza (None, 3, 3, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_relu_7 (LeakyReLU)     (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_batchnorm_8 (QConv2DB (None, 3, 3, 256)         591105    \n",
      "_________________________________________________________________\n",
      "leaky_relu_8 (LeakyReLU)     (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               589824    \n",
      "_________________________________________________________________\n",
      "batch_norm_10 (BatchNormaliz (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "leaky_relu_9 (LeakyReLU)     (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65536     \n",
      "_________________________________________________________________\n",
      "batch_norm_11 (BatchNormaliz (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "leaky_relu_10 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activate (Activation)        (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,838,482\n",
      "Trainable params: 1,835,497\n",
      "Non-trainable params: 2,985\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input1 = Input(shape=(56, 11, 4), name='em_barrel')\n",
    "x1 = UpSampling2D(size=(1, 5), interpolation='nearest',\n",
    "                    data_format='channels_last', name='up_sampling')(input1)\n",
    "x2 = BatchNormalization(name='batch_norm',epsilon=25)(x1)\n",
    "x2 = Conv2D(16, kernel_size=(5,5), strides=(1,1), kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001), use_bias=False,\n",
    "               name='conv', padding='same')(x2) \n",
    "x3 = BatchNormalization(name='batch_norm_1')(x2)\n",
    "x4 = LeakyReLU(alpha = 0.30000001192092896, name='leaky_relu')(x3)\n",
    "x5 = MaxPooling2D((2,2), name='max_pooling2D')(x4)\n",
    "x6 = Conv2D(32, kernel_size=(3,3), strides=(1,1), kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001), use_bias=False,\n",
    "               name='conv_1', padding='same')(x5) \n",
    "x6 = BatchNormalization(name='batch_norm_2')(x6)\n",
    "x7 = LeakyReLU(alpha = 0.30000001192092896, name='leaky_relu_1')(x6)\n",
    "x8 = Conv2D(32, kernel_size=(3,3), strides=(1,1), kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001), use_bias=False,\n",
    "               name='conv_2', padding='same')(x7) \n",
    "x8 = BatchNormalization(name='batch_norm_3')(x8)\n",
    "x9 = LeakyReLU(alpha = 0.30000001192092896, name='leaky_relu_2')(x8)\n",
    "x10 = MaxPooling2D((2,2), name='max_pooling2D_1')(x9)\n",
    "x11 = Conv2D(64, kernel_size=(3,3), strides=(1,1), kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001), use_bias=False,\n",
    "               name='conv_3', padding='same')(x10)\n",
    "x11 = BatchNormalization(name='batch_norm_4')(x11)\n",
    "x12 = LeakyReLU(alpha = 0.30000001192092896, name='leaky_relu_3')(x11)\n",
    "x13 = Conv2D(64, kernel_size=(3,3), strides=(1,1), kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001), use_bias=False,\n",
    "               name='conv_4', padding='same')(x12) \n",
    "x13 = BatchNormalization(name='batch_norm_5')(x13)\n",
    "x14 = LeakyReLU(alpha = 0.30000001192092896, name='leaky_relu_4')(x13)\n",
    "x15 = MaxPooling2D((2,2), name='max_pooling2D_2')(x14)\n",
    "x16 = Conv2D(128, kernel_size=(3,3), strides=(1,1), kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001), use_bias=False,\n",
    "               name='conv_5', padding='same')(x15) \n",
    "x16 = BatchNormalization(name='batch_norm_6')(x16)\n",
    "x17 = LeakyReLU(alpha = 0.30000001192092896, name='leaky_relu_5')(x16)\n",
    "x18 = Conv2D(128, kernel_size=(3,3), strides=(1,1), kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001), use_bias=False,\n",
    "               name='conv_6', padding='same')(x17) \n",
    "x18 = BatchNormalization(name='batch_norm_7')(x18)\n",
    "x19 = LeakyReLU(alpha = 0.30000001192092896, name='leaky_relu_6')(x18)\n",
    "x20 = MaxPooling2D((2,2), name='max_pooling2D_3')(x19)\n",
    "x21 = Conv2D(256, kernel_size=(3,3), strides=(1,1), kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001), use_bias=False,\n",
    "               name='conv_7', padding='same')(x20) \n",
    "x21 = BatchNormalization(name='batch_norm_8')(x21)\n",
    "x22 = LeakyReLU(alpha = 0.30000001192092896, name='leaky_relu_7')(x21)\n",
    "x23 = QConv2DBatchnorm(256, kernel_size=(3,3), strides=(1,1),\n",
    "                         kernel_quantizer=\"quantized_bits(16,4,alpha=1)\", \n",
    "                         bias_quantizer=\"quantized_bits(16,4,alpha=1)\",\n",
    "                         kernel_initializer='lecun_uniform', \n",
    "                         kernel_regularizer=l1(0.0001), \n",
    "                         use_bias=True,\n",
    "                         padding='same',\n",
    "                         name='conv2d_batchnorm_8')(x22)\n",
    "x24 = LeakyReLU(alpha = 0.30000001192092896, name='leaky_relu_8')(x23)\n",
    "x25 = Flatten(name='flatten')(x24)\n",
    "x26 = Dense(256, name='dense', #kernel_quantizer=quantized_bits(32,16,alpha='auto_po2'),\n",
    "                               kernel_initializer='lecun_uniform',\n",
    "                               kernel_regularizer=l1(0.0001),\n",
    "                               use_bias=False)(x25)\n",
    "x27 = BatchNormalization(name='batch_norm_10')(x26)\n",
    "x28 = LeakyReLU(alpha = 0.30000001192092896, name='leaky_relu_9')(x27)\n",
    "x29 = Dense(256, name='dense_1', #kernel_quantizer=quantized_bits(32,16,alpha='auto_po2'),\n",
    "                               kernel_initializer='lecun_uniform',\n",
    "                               kernel_regularizer=l1(0.0001),\n",
    "                               use_bias=False)(x28)\n",
    "x30 = BatchNormalization(name='batch_norm_11')(x29)\n",
    "x31 = LeakyReLU(alpha = 0.30000001192092896, name='leaky_relu_10')(x30)\n",
    "x32 = Dense(1, name='dense_2', #kernel_quantizer=quantized_bits(32,16,alpha='auto_po2'),\n",
    "                               #bias_quantizer=quantized_bits(32,16,alpha='auto_po2'),\n",
    "                               kernel_initializer='lecun_uniform',\n",
    "                               kernel_regularizer=l1(0.0001),\n",
    "                               use_bias=True)(x31)\n",
    "output1 = Activation(name='activate', activation='relu')(x32)\n",
    "\n",
    "\n",
    "model = Model(inputs= [input1], outputs=[output1], name='model')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "3c3c67f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "em_barrel (InputLayer)       [(None, 56, 11, 4)]       0         \n",
      "_________________________________________________________________\n",
      "up_sampling (UpSampling2D)   (None, 56, 55, 4)         0         \n",
      "_________________________________________________________________\n",
      "batch_norm (BatchNormalizati (None, 56, 55, 4)         16        \n",
      "_________________________________________________________________\n",
      "conv2d_batchnorm (QConv2DBat (None, 56, 55, 16)        1681      \n",
      "_________________________________________________________________\n",
      "leaky_relu (LeakyReLU)       (None, 56, 55, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2D (MaxPooling2D) (None, 28, 27, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_batchnorm_1 (QConv2DB (None, 28, 27, 32)        4769      \n",
      "_________________________________________________________________\n",
      "leaky_relu_1 (LeakyReLU)     (None, 28, 27, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_batchnorm_2 (QConv2DB (None, 28, 27, 32)        9377      \n",
      "_________________________________________________________________\n",
      "leaky_relu_2 (LeakyReLU)     (None, 28, 27, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2D_1 (MaxPooling2 (None, 14, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_batchnorm_3 (QConv2DB (None, 14, 13, 64)        18753     \n",
      "_________________________________________________________________\n",
      "leaky_relu_3 (LeakyReLU)     (None, 14, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_batchnorm_4 (QConv2DB (None, 14, 13, 64)        37185     \n",
      "_________________________________________________________________\n",
      "leaky_relu_4 (LeakyReLU)     (None, 14, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2D_2 (MaxPooling2 (None, 7, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_batchnorm_5 (QConv2DB (None, 7, 6, 128)         74369     \n",
      "_________________________________________________________________\n",
      "leaky_relu_5 (LeakyReLU)     (None, 7, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_batchnorm_6 (QConv2DB (None, 7, 6, 128)         148097    \n",
      "_________________________________________________________________\n",
      "leaky_relu_6 (LeakyReLU)     (None, 7, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2D_3 (MaxPooling2 (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_batchnorm_7 (QConv2DB (None, 3, 3, 256)         296193    \n",
      "_________________________________________________________________\n",
      "leaky_relu_7 (LeakyReLU)     (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_batchnorm_8 (QConv2DB (None, 3, 3, 256)         591105    \n",
      "_________________________________________________________________\n",
      "leaky_relu_8 (LeakyReLU)     (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense (QDense)               (None, 256)               589824    \n",
      "_________________________________________________________________\n",
      "batch_norm_1 (BatchNormaliza (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "leaky_relu_9 (LeakyReLU)     (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (QDense)             (None, 256)               65536     \n",
      "_________________________________________________________________\n",
      "batch_norm_2 (BatchNormaliza (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "leaky_relu_10 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (QDense)             (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activate (Activation)        (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,839,210\n",
      "Trainable params: 1,836,217\n",
      "Non-trainable params: 2,993\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input1 = Input(shape=(56, 11, 4), name='em_barrel')\n",
    "x1 = UpSampling2D(size=(1, 5), interpolation='nearest',\n",
    "                    data_format='channels_last', name='up_sampling')(input1)\n",
    "x2 = BatchNormalization(name='batch_norm',epsilon=25)(x1)\n",
    "x3 = QConv2DBatchnorm(16, kernel_size=(5,5), strides=(1,1),\n",
    "                         kernel_quantizer=\"quantized_bits(16,10,alpha=1)\", \n",
    "                         bias_quantizer=\"quantized_bits(16,10,alpha=1)\",\n",
    "                         kernel_initializer='lecun_uniform', \n",
    "                         kernel_regularizer=l1(0.0001), \n",
    "                         use_bias=True,\n",
    "                         padding='same',\n",
    "                         name='conv2d_batchnorm')(x2)\n",
    "x4 = LeakyReLU(alpha = 0.30000001192092896, name='leaky_relu')(x3)\n",
    "x5 = MaxPooling2D((2,2), name='max_pooling2D')(x4)\n",
    "x6 = QConv2DBatchnorm(32, kernel_size=(3,3), strides=(1,1),\n",
    "                         kernel_quantizer=\"quantized_bits(16,2,alpha=1)\", \n",
    "                         bias_quantizer=\"quantized_bits(16,10,alpha=1)\",\n",
    "                         kernel_initializer='lecun_uniform', \n",
    "                         kernel_regularizer=l1(0.0001), \n",
    "                         use_bias=True,\n",
    "                         padding='same',\n",
    "                         name='conv2d_batchnorm_1')(x5)\n",
    "x7 = LeakyReLU(alpha = 0.30000001192092896, name='leaky_relu_1')(x6)\n",
    "x8 = QConv2DBatchnorm(32, kernel_size=(3,3), strides=(1,1),\n",
    "                         kernel_quantizer=\"quantized_bits(16,2,alpha=1)\", \n",
    "                         bias_quantizer=\"quantized_bits(16,10,alpha=1)\",\n",
    "                         kernel_initializer='lecun_uniform', \n",
    "                         kernel_regularizer=l1(0.0001),\n",
    "                         use_bias=True,\n",
    "                         padding='same',\n",
    "                         name='conv2d_batchnorm_2')(x7)\n",
    "x9 = LeakyReLU(alpha = 0.30000001192092896, name='leaky_relu_2')(x8)\n",
    "x10 = MaxPooling2D((2,2), name='max_pooling2D_1')(x9)\n",
    "x11 = QConv2DBatchnorm(64, kernel_size=(3,3), strides=(1,1),\n",
    "                         kernel_quantizer=\"quantized_bits(16,2,alpha=1)\", \n",
    "                         bias_quantizer=\"quantized_bits(16,10,alpha=1)\",\n",
    "                         kernel_initializer='lecun_uniform', \n",
    "                         kernel_regularizer=l1(0.0001), \n",
    "                         use_bias=True,\n",
    "                         padding='same',\n",
    "                         name='conv2d_batchnorm_3')(x10)\n",
    "x12 = LeakyReLU(alpha = 0.30000001192092896, name='leaky_relu_3')(x11)\n",
    "x13 = QConv2DBatchnorm(64, kernel_size=(3,3), strides=(1,1),\n",
    "                         kernel_quantizer=\"quantized_bits(16,2,alpha=1)\", \n",
    "                         bias_quantizer=\"quantized_bits(16,10,alpha=1)\",\n",
    "                         kernel_initializer='lecun_uniform', \n",
    "                         kernel_regularizer=l1(0.0001), \n",
    "                         use_bias=True,\n",
    "                         padding='same',\n",
    "                         name='conv2d_batchnorm_4')(x12)\n",
    "x14 = LeakyReLU(alpha = 0.30000001192092896, name='leaky_relu_4')(x13)\n",
    "x15 = MaxPooling2D((2,2), name='max_pooling2D_2')(x14)\n",
    "x16 = QConv2DBatchnorm(128, kernel_size=(3,3), strides=(1,1),\n",
    "                         kernel_quantizer=\"quantized_bits(16,2,alpha=1)\", \n",
    "                         bias_quantizer=\"quantized_bits(16,10,alpha=1)\",\n",
    "                         kernel_initializer='lecun_uniform', \n",
    "                         kernel_regularizer=l1(0.0001), \n",
    "                         use_bias=True,\n",
    "                         padding='same',\n",
    "                         name='conv2d_batchnorm_5')(x15)\n",
    "x17 = LeakyReLU(alpha = 0.30000001192092896, name='leaky_relu_5')(x16)\n",
    "x18 = QConv2DBatchnorm(128, kernel_size=(3,3), strides=(1,1),\n",
    "                         kernel_quantizer=\"quantized_bits(16,2,alpha=1)\", \n",
    "                         bias_quantizer=\"quantized_bits(16,10,alpha=1)\",\n",
    "                         kernel_initializer='lecun_uniform', \n",
    "                         kernel_regularizer=l1(0.0001), \n",
    "                         use_bias=True,\n",
    "                         padding='same',\n",
    "                         name='conv2d_batchnorm_6')(x17)\n",
    "x19 = LeakyReLU(alpha = 0.30000001192092896, name='leaky_relu_6')(x18)\n",
    "x20 = MaxPooling2D((2,2), name='max_pooling2D_3')(x19)\n",
    "x21 = QConv2DBatchnorm(256, kernel_size=(3,3), strides=(1,1),\n",
    "                         kernel_quantizer=\"quantized_bits(16,2,alpha=1)\", \n",
    "                         bias_quantizer=\"quantized_bits(16,10,alpha=1)\",\n",
    "                         kernel_initializer='lecun_uniform', \n",
    "                         kernel_regularizer=l1(0.0001), \n",
    "                         use_bias=True,\n",
    "                         padding='same',\n",
    "                         name='conv2d_batchnorm_7')(x20)\n",
    "x22 = LeakyReLU(alpha = 0.30000001192092896, name='leaky_relu_7')(x21)\n",
    "x23 = QConv2DBatchnorm(256, kernel_size=(3,3), strides=(1,1),\n",
    "                         kernel_quantizer=\"quantized_bits(16,2,alpha=1)\", \n",
    "                         bias_quantizer=\"quantized_bits(16,10,alpha=1)\",\n",
    "                         kernel_initializer='lecun_uniform', \n",
    "                         kernel_regularizer=l1(0.0001), \n",
    "                         use_bias=True,\n",
    "                         padding='same',\n",
    "                         name='conv2d_batchnorm_8')(x22)\n",
    "x24 = LeakyReLU(alpha = 0.30000001192092896, name='leaky_relu_8')(x23)\n",
    "x25 = Flatten(name='flatten')(x24)\n",
    "x26 = QDense(256, name='dense', kernel_quantizer=quantized_bits(16,10,alpha=1),\n",
    "                               kernel_initializer='lecun_uniform',\n",
    "                               kernel_regularizer=l1(0.0001),\n",
    "                               use_bias=False)(x25)\n",
    "x27 = BatchNormalization(name='batch_norm_1')(x26)\n",
    "x28 = LeakyReLU(alpha = 0.30000001192092896, name='leaky_relu_9')(x27)\n",
    "x29 = QDense(256, name='dense_1', kernel_quantizer=quantized_bits(16,10,alpha=1),\n",
    "                               kernel_initializer='lecun_uniform',\n",
    "                               kernel_regularizer=l1(0.0001),\n",
    "                               use_bias=False)(x28)\n",
    "x30 = BatchNormalization(name='batch_norm_2')(x29)\n",
    "x31 = LeakyReLU(alpha = 0.30000001192092896, name='leaky_relu_10')(x30)\n",
    "x32 = QDense(1, name='dense_2', kernel_quantizer=quantized_bits(16,10,alpha=1),\n",
    "                               bias_quantizer=quantized_bits(16,10,alpha=1),\n",
    "                               kernel_initializer='lecun_uniform',\n",
    "                               kernel_regularizer=l1(0.0001),\n",
    "                               use_bias=True)(x31)\n",
    "output1 = Activation(name='activate', activation='relu')(x32)\n",
    "\n",
    "\n",
    "model = Model(inputs= [input1], outputs=[output1], name='model')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6990f7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_model_optimization.python.core.sparsity.keras import prune, pruning_callbacks, pruning_schedule\n",
    "from tensorflow_model_optimization.sparsity.keras import strip_pruning\n",
    "pruning_params = {\"pruning_schedule\" : pruning_schedule.ConstantSparsity(0.75, begin_step=1000, frequency=100)}\n",
    "model = prune.prune_low_magnitude(model, **pruning_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab877d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "52eb216d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hisky/anaconda3/envs/hls4ml--py37/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "2022-05-05 15:57:45.054393: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2022-05-05 15:57:45.054428: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n",
      "2022-05-05 15:57:45.054664: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1/9 [==>...........................] - ETA: 42s - loss: 85.0653 - mae: 80.8652"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 15:57:50.596519: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\n",
      "2022-05-05 15:57:50.596564: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "2/9 [=====>........................] - ETA: 17s - loss: 85.0701 - mae: 80.8715"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 15:57:53.484415: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-05-05 15:57:53.493346: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\n",
      "2022-05-05 15:57:53.503891: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: keras_model_162InConvWeight/logs/train/plugins/profile/2022_05_05_15_57_53\n",
      "2022-05-05 15:57:53.509837: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to keras_model_162InConvWeight/logs/train/plugins/profile/2022_05_05_15_57_53/r7515ed520.trace.json.gz\n",
      "2022-05-05 15:57:53.517315: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: keras_model_162InConvWeight/logs/train/plugins/profile/2022_05_05_15_57_53\n",
      "2022-05-05 15:57:53.517439: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to keras_model_162InConvWeight/logs/train/plugins/profile/2022_05_05_15_57_53/r7515ed520.memory_profile.json.gz\n",
      "2022-05-05 15:57:53.518365: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: keras_model_162InConvWeight/logs/train/plugins/profile/2022_05_05_15_57_53Dumped tool data for xplane.pb to keras_model_162InConvWeight/logs/train/plugins/profile/2022_05_05_15_57_53/r7515ed520.xplane.pb\n",
      "Dumped tool data for overview_page.pb to keras_model_162InConvWeight/logs/train/plugins/profile/2022_05_05_15_57_53/r7515ed520.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to keras_model_162InConvWeight/logs/train/plugins/profile/2022_05_05_15_57_53/r7515ed520.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to keras_model_162InConvWeight/logs/train/plugins/profile/2022_05_05_15_57_53/r7515ed520.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to keras_model_162InConvWeight/logs/train/plugins/profile/2022_05_05_15_57_53/r7515ed520.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 26s 3s/step - loss: 81.9023 - mae: 77.6845 - val_loss: 68.6671 - val_mae: 64.4312\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 68.66705, saving model to keras_model_162InConvWeight/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 68.66705, saving model to keras_model_162InConvWeight/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00001: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00001: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 21s 2s/step - loss: 78.0981 - mae: 73.9058 - val_loss: 157.3317 - val_mae: 153.2377\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 68.66705\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 68.66705\n",
      "\n",
      "Epoch 00002: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00002: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 74.9327 - mae: 70.9597 - val_loss: 173.0284 - val_mae: 169.2384\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 68.66705\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 68.66705\n",
      "\n",
      "Epoch 00003: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00003: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 71.2345 - mae: 67.6112 - val_loss: 67.9965 - val_mae: 64.5972\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00004: val_loss improved from 68.66705 to 67.99648, saving model to keras_model_162InConvWeight/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00004: val_loss improved from 68.66705 to 67.99648, saving model to keras_model_162InConvWeight/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00004: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00004: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 67.3078 - mae: 64.0739 - val_loss: 49.6917 - val_mae: 46.6547\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00005: val_loss improved from 67.99648 to 49.69174, saving model to keras_model_162InConvWeight/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00005: val_loss improved from 67.99648 to 49.69174, saving model to keras_model_162InConvWeight/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00005: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00005: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 63.0510 - mae: 60.1508 - val_loss: 65.2305 - val_mae: 62.4927\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 49.69174\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 49.69174\n",
      "\n",
      "Epoch 00006: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00006: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 58.8885 - mae: 56.2481 - val_loss: 84.9832 - val_mae: 82.4598\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 49.69174\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 49.69174\n",
      "\n",
      "Epoch 00007: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00007: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 53.9778 - mae: 51.5147 - val_loss: 146.7579 - val_mae: 144.3775\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 49.69174\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 49.69174\n",
      "\n",
      "Epoch 00008: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00008: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 52.5938 - mae: 50.0943 - val_loss: 55.5213 - val_mae: 52.6938\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 49.69174\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 49.69174\n",
      "\n",
      "Epoch 00009: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00009: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 49.9004 - mae: 46.8942 - val_loss: 46.6805 - val_mae: 43.5092\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00010: val_loss improved from 49.69174 to 46.68053, saving model to keras_model_162InConvWeight/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00010: val_loss improved from 49.69174 to 46.68053, saving model to keras_model_162InConvWeight/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00010: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00010: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00010: saving model to keras_model_162InConvWeight/KERAS_check_model_epoch10.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 44.7608 - mae: 41.5478 - val_loss: 98.0607 - val_mae: 94.8268\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 46.68053\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 46.68053\n",
      "\n",
      "Epoch 00011: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00011: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 39.2148 - mae: 35.9895 - val_loss: 135.5726 - val_mae: 132.3577\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 46.68053\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 46.68053\n",
      "\n",
      "Epoch 00012: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00012: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 35.1949 - mae: 32.0139 - val_loss: 196.4277 - val_mae: 193.2984\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 46.68053\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 46.68053\n",
      "\n",
      "Epoch 00013: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00013: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 33.2207 - mae: 30.1015 - val_loss: 70.5502 - val_mae: 67.3636\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 46.68053\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 46.68053\n",
      "\n",
      "Epoch 00014: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00014: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 30.8610 - mae: 27.5813 - val_loss: 53.0246 - val_mae: 49.6609\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 46.68053\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 46.68053\n",
      "\n",
      "Epoch 00015: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00015: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 16/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 20s 2s/step - loss: 27.6507 - mae: 24.2590 - val_loss: 78.9691 - val_mae: 75.5516\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 46.68053\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 46.68053\n",
      "\n",
      "Epoch 00016: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00016: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 25.0949 - mae: 21.6852 - val_loss: 36.1903 - val_mae: 32.7880\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00017: val_loss improved from 46.68053 to 36.19027, saving model to keras_model_162InConvWeight/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00017: val_loss improved from 46.68053 to 36.19027, saving model to keras_model_162InConvWeight/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00017: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00017: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 23.7651 - mae: 20.3826 - val_loss: 52.4046 - val_mae: 49.0528\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 36.19027\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 36.19027\n",
      "\n",
      "Epoch 00018: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00018: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 22.7667 - mae: 19.4450 - val_loss: 33.0724 - val_mae: 29.7882\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00019: val_loss improved from 36.19027 to 33.07240, saving model to keras_model_162InConvWeight/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00019: val_loss improved from 36.19027 to 33.07240, saving model to keras_model_162InConvWeight/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00019: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00019: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 21.6210 - mae: 18.3579 - val_loss: 32.7283 - val_mae: 29.5107\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00020: val_loss improved from 33.07240 to 32.72828, saving model to keras_model_162InConvWeight/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00020: val_loss improved from 33.07240 to 32.72828, saving model to keras_model_162InConvWeight/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00020: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00020: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00020: saving model to keras_model_162InConvWeight/KERAS_check_model_epoch20.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 20.9756 - mae: 17.8004 - val_loss: 73.0441 - val_mae: 69.9234\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00021: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00021: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 20.3892 - mae: 17.3130 - val_loss: 56.8365 - val_mae: 53.8239\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00022: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00022: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 19.6290 - mae: 16.6699 - val_loss: 42.5314 - val_mae: 39.6314\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00023: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00023: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 25.7714 - mae: 22.8369 - val_loss: 44.1853 - val_mae: 40.9386\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00024: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00024: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 32.3089 - mae: 28.7144 - val_loss: 86.6300 - val_mae: 82.6279\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00025: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00025: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 27.0313 - mae: 22.8062 - val_loss: 86.0004 - val_mae: 81.5500\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00026: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00026: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 24.9061 - mae: 20.3752 - val_loss: 71.1541 - val_mae: 66.5648\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00027: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00027: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 23.3566 - mae: 18.7713 - val_loss: 71.9023 - val_mae: 67.3422\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00028: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00028: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 22.3120 - mae: 17.7929 - val_loss: 85.2885 - val_mae: 80.8292\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00029: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00029: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 21.8346 - mae: 17.4251 - val_loss: 82.4577 - val_mae: 78.1132\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00030: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00030: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00030: saving model to keras_model_162InConvWeight/KERAS_check_model_epoch30.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.001500000013038516.\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 21.2153 - mae: 16.8946 - val_loss: 86.8332 - val_mae: 82.5463\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00031: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00031: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 20.7776 - mae: 16.5176 - val_loss: 86.8289 - val_mae: 82.6074\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00032: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00032: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 20.4861 - mae: 16.2929 - val_loss: 86.6441 - val_mae: 82.4885\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00033: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00033: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 20.1068 - mae: 15.9822 - val_loss: 86.5237 - val_mae: 82.4402\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00034: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00034: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 19.9929 - mae: 15.9397 - val_loss: 86.3253 - val_mae: 82.3124\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00035: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00035: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 19.5427 - mae: 15.5579 - val_loss: 86.2804 - val_mae: 82.3318\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00036: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00036: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 19.7391 - mae: 15.8200 - val_loss: 86.2409 - val_mae: 82.3597\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00037: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00037: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 38/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 19.5742 - mae: 15.7215 - val_loss: 86.1174 - val_mae: 82.3015\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00038: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00038: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 39/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 19.4056 - mae: 15.6158 - val_loss: 86.1453 - val_mae: 82.3914\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00039: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00039: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 40/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 19.2811 - mae: 15.5534 - val_loss: 86.0590 - val_mae: 82.3660\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00040: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00040: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00040: saving model to keras_model_162InConvWeight/KERAS_check_model_epoch40.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 41/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 19.0039 - mae: 15.3361 - val_loss: 86.0596 - val_mae: 82.4269\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00041: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00041: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.000750000006519258.\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 42/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 18.9521 - mae: 15.3326 - val_loss: 85.8809 - val_mae: 82.2789\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00042: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00042: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 43/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 18.8497 - mae: 15.2607 - val_loss: 85.8015 - val_mae: 82.2303\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00043: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00043: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 44/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 18.8242 - mae: 15.2648 - val_loss: 85.7420 - val_mae: 82.1993\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00044: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00044: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 45/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 18.7650 - mae: 15.2361 - val_loss: 85.5067 - val_mae: 81.9949\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00045: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00045: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 46/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 18.5254 - mae: 15.0260 - val_loss: 85.2344 - val_mae: 81.7512\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00046: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00046: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 47/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 20s 2s/step - loss: 18.5515 - mae: 15.0819 - val_loss: 84.3006 - val_mae: 80.8476\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00047: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00047: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 48/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 18.5238 - mae: 15.0829 - val_loss: 83.1447 - val_mae: 79.7197\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00048: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00048: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 49/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 18.5375 - mae: 15.1240 - val_loss: 83.4123 - val_mae: 80.0135\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00049: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00049: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 50/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 18.5290 - mae: 15.1421 - val_loss: 82.7183 - val_mae: 79.3483\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00050: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00050: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00050: saving model to keras_model_162InConvWeight/KERAS_check_model_epoch50.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 51/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 18.4234 - mae: 15.0640 - val_loss: 77.2284 - val_mae: 73.8858\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00051: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00051: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 52/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 18.3783 - mae: 15.0486 - val_loss: 76.2165 - val_mae: 72.9036\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00052: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00052: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.000375000003259629.\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 53/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 18.2410 - mae: 14.9350 - val_loss: 71.9225 - val_mae: 68.6244\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00053: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00053: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 54/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 18.1838 - mae: 14.8902 - val_loss: 66.4264 - val_mae: 63.1414\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00054: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00054: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 55/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 18.0470 - mae: 14.7663 - val_loss: 67.4548 - val_mae: 64.1820\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00055: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00055: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 56/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 18.1250 - mae: 14.8594 - val_loss: 66.6176 - val_mae: 63.3603\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00056: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00056: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 57/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 18.1290 - mae: 14.8760 - val_loss: 62.0269 - val_mae: 58.7822\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00057: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00057: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 58/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.9938 - mae: 14.7544 - val_loss: 60.9828 - val_mae: 57.7502\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00058: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00058: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 59/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 18.0893 - mae: 14.8624 - val_loss: 60.0971 - val_mae: 56.8767\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00059: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00059: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 60/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 18.1238 - mae: 14.9080 - val_loss: 59.3839 - val_mae: 56.1758\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00060: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00060: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00060: saving model to keras_model_162InConvWeight/KERAS_check_model_epoch60.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 61/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 18.1205 - mae: 14.9175 - val_loss: 56.5078 - val_mae: 53.3125\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00061: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00061: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 62/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.9344 - mae: 14.7437 - val_loss: 56.4227 - val_mae: 53.2383\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00062: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00062: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 63/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 20s 2s/step - loss: 18.2948 - mae: 15.1166 - val_loss: 52.3735 - val_mae: 49.2028\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00063: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00063: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 0.0001875000016298145.\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 64/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.9229 - mae: 14.7558 - val_loss: 50.7481 - val_mae: 47.5841\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00064: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00064: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 65/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.9694 - mae: 14.8085 - val_loss: 49.7911 - val_mae: 46.6345\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00065: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00065: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 66/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.8782 - mae: 14.7244 - val_loss: 50.6770 - val_mae: 47.5260\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00066: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00066: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 67/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.8736 - mae: 14.7256 - val_loss: 49.6743 - val_mae: 46.5304\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00067: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00067: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 68/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.7054 - mae: 14.5647 - val_loss: 49.6792 - val_mae: 46.5427\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00068: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00068: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 69/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.6821 - mae: 14.5477 - val_loss: 49.8194 - val_mae: 46.6886\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00069: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00069: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 70/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.6992 - mae: 14.5709 - val_loss: 48.9845 - val_mae: 45.8613\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00070: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00070: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00070: saving model to keras_model_162InConvWeight/KERAS_check_model_epoch70.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 71/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.6673 - mae: 14.5463 - val_loss: 48.2947 - val_mae: 45.1768\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00071: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00071: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 72/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.6462 - mae: 14.5317 - val_loss: 46.1957 - val_mae: 43.0860\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00072: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00072: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 73/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.6366 - mae: 14.5296 - val_loss: 34.0560 - val_mae: 30.9528\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 32.72828\n",
      "\n",
      "Epoch 00073: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00073: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 74/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.5984 - mae: 14.4986 - val_loss: 30.4467 - val_mae: 27.3503\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00074: val_loss improved from 32.72828 to 30.44668, saving model to keras_model_162InConvWeight/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00074: val_loss improved from 32.72828 to 30.44668, saving model to keras_model_162InConvWeight/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00074: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00074: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 75/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.5750 - mae: 14.4809 - val_loss: 30.1778 - val_mae: 27.0865\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00075: val_loss improved from 30.44668 to 30.17776, saving model to keras_model_162InConvWeight/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00075: val_loss improved from 30.44668 to 30.17776, saving model to keras_model_162InConvWeight/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00075: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00075: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 76/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.5385 - mae: 14.4499 - val_loss: 30.3407 - val_mae: 27.2564\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 30.17776\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 30.17776\n",
      "\n",
      "Epoch 00076: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00076: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 77/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.6258 - mae: 14.5442 - val_loss: 29.5172 - val_mae: 26.4391\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00077: val_loss improved from 30.17776 to 29.51720, saving model to keras_model_162InConvWeight/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00077: val_loss improved from 30.17776 to 29.51720, saving model to keras_model_162InConvWeight/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00077: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00077: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 78/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 20s 2s/step - loss: 17.5913 - mae: 14.5155 - val_loss: 28.7671 - val_mae: 25.6955\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00078: val_loss improved from 29.51720 to 28.76706, saving model to keras_model_162InConvWeight/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00078: val_loss improved from 29.51720 to 28.76706, saving model to keras_model_162InConvWeight/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00078: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00078: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 79/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.6452 - mae: 14.5760 - val_loss: 24.4001 - val_mae: 21.3346\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00079: val_loss improved from 28.76706 to 24.40009, saving model to keras_model_162InConvWeight/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00079: val_loss improved from 28.76706 to 24.40009, saving model to keras_model_162InConvWeight/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00079: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00079: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 80/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.5627 - mae: 14.5000 - val_loss: 24.4690 - val_mae: 21.4102\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 24.40009\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 24.40009\n",
      "\n",
      "Epoch 00080: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00080: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00080: saving model to keras_model_162InConvWeight/KERAS_check_model_epoch80.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 81/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.5799 - mae: 14.5221 - val_loss: 25.8241 - val_mae: 22.7687\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 24.40009\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 24.40009\n",
      "\n",
      "Epoch 00081: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00081: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 82/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.5606 - mae: 14.5096 - val_loss: 25.8723 - val_mae: 22.8249\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 24.40009\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 24.40009\n",
      "\n",
      "Epoch 00082: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00082: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 83/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.5546 - mae: 14.5090 - val_loss: 28.2724 - val_mae: 25.2312\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 24.40009\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 24.40009\n",
      "\n",
      "Epoch 00083: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00083: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 84/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.4736 - mae: 14.4353 - val_loss: 27.3138 - val_mae: 24.2785\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 24.40009\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 24.40009\n",
      "\n",
      "Epoch 00084: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00084: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 85/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.4766 - mae: 14.4449 - val_loss: 26.7900 - val_mae: 23.7626\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 24.40009\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 24.40009\n",
      "\n",
      "Epoch 00085: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00085: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 86/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.5353 - mae: 14.5096 - val_loss: 25.1724 - val_mae: 22.1509\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 24.40009\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 24.40009\n",
      "\n",
      "Epoch 00086: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00086: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 87/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.4179 - mae: 14.3985 - val_loss: 23.3286 - val_mae: 20.3115\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00087: val_loss improved from 24.40009 to 23.32862, saving model to keras_model_162InConvWeight/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00087: val_loss improved from 24.40009 to 23.32862, saving model to keras_model_162InConvWeight/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00087: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00087: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 88/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.5100 - mae: 14.4952 - val_loss: 24.0008 - val_mae: 20.9905\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 23.32862\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 23.32862\n",
      "\n",
      "Epoch 00088: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00088: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 89/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.4072 - mae: 14.3999 - val_loss: 23.6799 - val_mae: 20.6762\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 23.32862\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 23.32862\n",
      "\n",
      "Epoch 00089: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00089: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 90/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.5084 - mae: 14.5062 - val_loss: 25.4893 - val_mae: 22.4910\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 23.32862\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 23.32862\n",
      "\n",
      "Epoch 00090: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00090: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00090: saving model to keras_model_162InConvWeight/KERAS_check_model_epoch90.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 91/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.4666 - mae: 14.4711 - val_loss: 24.5446 - val_mae: 21.5533\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 23.32862\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 23.32862\n",
      "\n",
      "Epoch 00091: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00091: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 92/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.3290 - mae: 14.3405 - val_loss: 24.3274 - val_mae: 21.3415\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 23.32862\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 23.32862\n",
      "\n",
      "Epoch 00092: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00092: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 93/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 20s 2s/step - loss: 17.4240 - mae: 14.4405 - val_loss: 25.2829 - val_mae: 22.3025\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 23.32862\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 23.32862\n",
      "\n",
      "Epoch 00093: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00093: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 94/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.5168 - mae: 14.5391 - val_loss: 24.6317 - val_mae: 21.6567\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 23.32862\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 23.32862\n",
      "\n",
      "Epoch 00094: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00094: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 95/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.4069 - mae: 14.4329 - val_loss: 23.8027 - val_mae: 20.8314\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 23.32862\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 23.32862\n",
      "\n",
      "Epoch 00095: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00095: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 96/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.2560 - mae: 14.2886 - val_loss: 24.1479 - val_mae: 21.1849\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 23.32862\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 23.32862\n",
      "\n",
      "Epoch 00096: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00096: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 97/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.3023 - mae: 14.3426 - val_loss: 24.3213 - val_mae: 21.3649\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 23.32862\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 23.32862\n",
      "\n",
      "Epoch 00097: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00097: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 9.375000081490725e-05.\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 98/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.3170 - mae: 14.3619 - val_loss: 24.9852 - val_mae: 22.0330\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 23.32862\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 23.32862\n",
      "\n",
      "Epoch 00098: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00098: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 99/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.3029 - mae: 14.3521 - val_loss: 25.3788 - val_mae: 22.4299\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 23.32862\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 23.32862\n",
      "\n",
      "Epoch 00099: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00099: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 100/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.2020 - mae: 14.2546 - val_loss: 25.0683 - val_mae: 22.1224\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 23.32862\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 23.32862\n",
      "\n",
      "Epoch 00100: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00100: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00100: saving model to keras_model_162InConvWeight/KERAS_check_model_epoch100.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 101/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.2427 - mae: 14.2988 - val_loss: 23.9429 - val_mae: 21.0013\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 23.32862\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 23.32862\n",
      "\n",
      "Epoch 00101: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00101: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 102/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.2286 - mae: 14.2882 - val_loss: 23.3623 - val_mae: 20.4236\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 23.32862\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 23.32862\n",
      "\n",
      "Epoch 00102: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00102: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 103/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.2710 - mae: 14.3333 - val_loss: 22.3346 - val_mae: 19.3992\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00103: val_loss improved from 23.32862 to 22.33461, saving model to keras_model_162InConvWeight/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00103: val_loss improved from 23.32862 to 22.33461, saving model to keras_model_162InConvWeight/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00103: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00103: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 104/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.2884 - mae: 14.3541 - val_loss: 21.7407 - val_mae: 18.8084\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00104: val_loss improved from 22.33461 to 21.74065, saving model to keras_model_162InConvWeight/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00104: val_loss improved from 22.33461 to 21.74065, saving model to keras_model_162InConvWeight/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00104: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00104: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 105/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.1776 - mae: 14.2466 - val_loss: 21.9772 - val_mae: 19.0479\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 21.74065\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 21.74065\n",
      "\n",
      "Epoch 00105: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00105: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 106/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.2586 - mae: 14.3303 - val_loss: 21.7774 - val_mae: 18.8509\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 21.74065\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 21.74065\n",
      "\n",
      "Epoch 00106: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00106: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 107/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.2630 - mae: 14.3366 - val_loss: 20.6686 - val_mae: 17.7444\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00107: val_loss improved from 21.74065 to 20.66862, saving model to keras_model_162InConvWeight/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00107: val_loss improved from 21.74065 to 20.66862, saving model to keras_model_162InConvWeight/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00107: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00107: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 108/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.3805 - mae: 14.4579 - val_loss: 19.3179 - val_mae: 16.3973\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00108: val_loss improved from 20.66862 to 19.31793, saving model to keras_model_162InConvWeight/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00108: val_loss improved from 20.66862 to 19.31793, saving model to keras_model_162InConvWeight/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00108: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00108: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 109/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.3638 - mae: 14.4442 - val_loss: 20.8032 - val_mae: 17.8855\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 19.31793\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 19.31793\n",
      "\n",
      "Epoch 00109: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00109: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 110/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.1566 - mae: 14.2403 - val_loss: 20.1069 - val_mae: 17.1925\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 19.31793\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 19.31793\n",
      "\n",
      "Epoch 00110: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00110: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00110: saving model to keras_model_162InConvWeight/KERAS_check_model_epoch110.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 111/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.1678 - mae: 14.2548 - val_loss: 18.7058 - val_mae: 15.7941\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00111: val_loss improved from 19.31793 to 18.70578, saving model to keras_model_162InConvWeight/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00111: val_loss improved from 19.31793 to 18.70578, saving model to keras_model_162InConvWeight/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00111: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00111: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 112/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.1508 - mae: 14.2406 - val_loss: 17.4236 - val_mae: 14.5151\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00112: val_loss improved from 18.70578 to 17.42356, saving model to keras_model_162InConvWeight/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00112: val_loss improved from 18.70578 to 17.42356, saving model to keras_model_162InConvWeight/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00112: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00112: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 113/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.2670 - mae: 14.3597 - val_loss: 17.6139 - val_mae: 14.7075\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 17.42356\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 17.42356\n",
      "\n",
      "Epoch 00113: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00113: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 114/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.2413 - mae: 14.3360 - val_loss: 17.0320 - val_mae: 14.1291\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00114: val_loss improved from 17.42356 to 17.03199, saving model to keras_model_162InConvWeight/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00114: val_loss improved from 17.42356 to 17.03199, saving model to keras_model_162InConvWeight/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00114: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00114: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 115/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.1688 - mae: 14.2672 - val_loss: 16.9470 - val_mae: 14.0472\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00115: val_loss improved from 17.03199 to 16.94700, saving model to keras_model_162InConvWeight/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00115: val_loss improved from 17.03199 to 16.94700, saving model to keras_model_162InConvWeight/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00115: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00115: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 116/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.1538 - mae: 14.2553 - val_loss: 17.1655 - val_mae: 14.2692\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 16.94700\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 16.94700\n",
      "\n",
      "Epoch 00116: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00116: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 117/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.2158 - mae: 14.3207 - val_loss: 17.0498 - val_mae: 14.1564\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 16.94700\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 16.94700\n",
      "\n",
      "Epoch 00117: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00117: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 118/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.1778 - mae: 14.2852 - val_loss: 17.3009 - val_mae: 14.4101\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 16.94700\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 16.94700\n",
      "\n",
      "Epoch 00118: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00118: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 119/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.4098 - mae: 14.5180 - val_loss: 17.3450 - val_mae: 14.4546\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 16.94700\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 16.94700\n",
      "\n",
      "Epoch 00119: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00119: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 120/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.2923 - mae: 14.4029 - val_loss: 17.2973 - val_mae: 14.4100\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 16.94700\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 16.94700\n",
      "\n",
      "Epoch 00120: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00120: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00120: saving model to keras_model_162InConvWeight/KERAS_check_model_epoch120.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 121/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.3986 - mae: 14.5121 - val_loss: 16.7863 - val_mae: 13.9011\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00121: val_loss improved from 16.94700 to 16.78628, saving model to keras_model_162InConvWeight/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00121: val_loss improved from 16.94700 to 16.78628, saving model to keras_model_162InConvWeight/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00121: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00121: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 122/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.2217 - mae: 14.3381 - val_loss: 16.5325 - val_mae: 13.6493\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00122: val_loss improved from 16.78628 to 16.53254, saving model to keras_model_162InConvWeight/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00122: val_loss improved from 16.78628 to 16.53254, saving model to keras_model_162InConvWeight/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00122: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00122: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 123/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.1322 - mae: 14.2513 - val_loss: 16.6160 - val_mae: 13.7378\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 16.53254\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 16.53254\n",
      "\n",
      "Epoch 00123: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00123: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 124/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.1634 - mae: 14.2853 - val_loss: 16.6231 - val_mae: 13.7475\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 16.53254\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 16.53254\n",
      "\n",
      "Epoch 00124: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00124: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 125/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.0991 - mae: 14.2255 - val_loss: 16.5919 - val_mae: 13.7206\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 16.53254\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 16.53254\n",
      "\n",
      "Epoch 00125: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00125: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 126/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.1313 - mae: 14.2613 - val_loss: 16.5850 - val_mae: 13.7165\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 16.53254\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 16.53254\n",
      "\n",
      "Epoch 00126: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00126: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 127/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.1811 - mae: 14.3139 - val_loss: 16.5733 - val_mae: 13.7082\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 16.53254\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 16.53254\n",
      "\n",
      "Epoch 00127: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00127: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 128/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.1542 - mae: 14.2901 - val_loss: 16.5038 - val_mae: 13.6416\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00128: val_loss improved from 16.53254 to 16.50383, saving model to keras_model_162InConvWeight/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00128: val_loss improved from 16.53254 to 16.50383, saving model to keras_model_162InConvWeight/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00128: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00128: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 129/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.2401 - mae: 14.3787 - val_loss: 16.6567 - val_mae: 13.7966\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 16.50383\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 16.50383\n",
      "\n",
      "Epoch 00129: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00129: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 130/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.1333 - mae: 14.2751 - val_loss: 16.9092 - val_mae: 14.0526\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 16.50383\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 16.50383\n",
      "\n",
      "Epoch 00130: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00130: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00130: saving model to keras_model_162InConvWeight/KERAS_check_model_epoch130.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 131/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.0722 - mae: 14.2170 - val_loss: 16.7281 - val_mae: 13.8749\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 16.50383\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 16.50383\n",
      "\n",
      "Epoch 00131: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00131: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 132/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.0994 - mae: 14.2473 - val_loss: 16.6830 - val_mae: 13.8326\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 16.50383\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 16.50383\n",
      "\n",
      "Epoch 00132: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00132: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 133/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.1248 - mae: 14.2755 - val_loss: 16.6206 - val_mae: 13.7729\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 16.50383\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 16.50383\n",
      "\n",
      "Epoch 00133: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00133: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 134/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.1723 - mae: 14.3249 - val_loss: 16.5620 - val_mae: 13.7171\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 16.50383\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 16.50383\n",
      "\n",
      "Epoch 00134: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00134: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 135/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.0823 - mae: 14.2387 - val_loss: 16.5290 - val_mae: 13.6872\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 16.50383\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 16.50383\n",
      "\n",
      "Epoch 00135: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00135: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 136/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.1200 - mae: 14.2790 - val_loss: 16.4797 - val_mae: 13.6401\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00136: val_loss improved from 16.50383 to 16.47971, saving model to keras_model_162InConvWeight/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00136: val_loss improved from 16.50383 to 16.47971, saving model to keras_model_162InConvWeight/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00136: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00136: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 137/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.0572 - mae: 14.2187 - val_loss: 16.5808 - val_mae: 13.7446\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 16.47971\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 16.47971\n",
      "\n",
      "Epoch 00137: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00137: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 138/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.1583 - mae: 14.3229 - val_loss: 16.6826 - val_mae: 13.8479\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 16.47971\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 16.47971\n",
      "\n",
      "Epoch 00138: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00138: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 139/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.1527 - mae: 14.3193 - val_loss: 16.7492 - val_mae: 13.9167\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 16.47971\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 16.47971\n",
      "\n",
      "Epoch 00139: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00139: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 140/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.1350 - mae: 14.3045 - val_loss: 16.6889 - val_mae: 13.8599\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 16.47971\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 16.47971\n",
      "\n",
      "Epoch 00140: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00140: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00140: saving model to keras_model_162InConvWeight/KERAS_check_model_epoch140.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 141/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.9540 - mae: 14.1266 - val_loss: 16.8197 - val_mae: 13.9938\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 16.47971\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 16.47971\n",
      "\n",
      "Epoch 00141: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00141: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 142/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.0635 - mae: 14.2391 - val_loss: 16.7737 - val_mae: 13.9514\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 16.47971\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 16.47971\n",
      "\n",
      "Epoch 00142: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00142: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 143/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.0225 - mae: 14.2015 - val_loss: 16.8573 - val_mae: 14.0381\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 16.47971\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 16.47971\n",
      "\n",
      "Epoch 00143: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00143: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 144/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.0625 - mae: 14.2444 - val_loss: 16.9376 - val_mae: 14.1212\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 16.47971\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 16.47971\n",
      "\n",
      "Epoch 00144: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00144: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 145/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.9852 - mae: 14.1694 - val_loss: 17.3048 - val_mae: 14.4905\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 16.47971\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 16.47971\n",
      "\n",
      "Epoch 00145: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00145: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 146/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.0710 - mae: 14.2581 - val_loss: 17.0296 - val_mae: 14.2191\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 16.47971\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 16.47971\n",
      "\n",
      "Epoch 00146: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00146: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00146: ReduceLROnPlateau reducing learning rate to 4.6875000407453626e-05.\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 147/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.0063 - mae: 14.1962 - val_loss: 16.9899 - val_mae: 14.1807\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 16.47971\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 16.47971\n",
      "\n",
      "Epoch 00147: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00147: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 148/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.0868 - mae: 14.2781 - val_loss: 18.8135 - val_mae: 16.0054\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 16.47971\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 16.47971\n",
      "\n",
      "Epoch 00148: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00148: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 149/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.9737 - mae: 14.1665 - val_loss: 17.3648 - val_mae: 14.5590\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 16.47971\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 16.47971\n",
      "\n",
      "Epoch 00149: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00149: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 150/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.0891 - mae: 14.2838 - val_loss: 16.9112 - val_mae: 14.1067\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 16.47971\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 16.47971\n",
      "\n",
      "Epoch 00150: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00150: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00150: saving model to keras_model_162InConvWeight/KERAS_check_model_epoch150.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 151/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.0177 - mae: 14.2137 - val_loss: 17.8537 - val_mae: 15.0502\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 16.47971\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 16.47971\n",
      "\n",
      "Epoch 00151: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00151: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 152/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.0452 - mae: 14.2427 - val_loss: 16.6864 - val_mae: 13.8852\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 16.47971\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 16.47971\n",
      "\n",
      "Epoch 00152: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00152: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 153/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 20s 2s/step - loss: 16.9296 - mae: 14.1292 - val_loss: 16.5248 - val_mae: 13.7249\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 16.47971\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 16.47971\n",
      "\n",
      "Epoch 00153: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00153: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 154/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.9858 - mae: 14.1864 - val_loss: 16.5626 - val_mae: 13.7638\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 16.47971\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 16.47971\n",
      "\n",
      "Epoch 00154: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00154: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 155/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.9997 - mae: 14.2020 - val_loss: 16.4915 - val_mae: 13.6949\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 16.47971\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 16.47971\n",
      "\n",
      "Epoch 00155: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00155: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 156/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.9680 - mae: 14.1719 - val_loss: 16.4773 - val_mae: 13.6821\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00156: val_loss improved from 16.47971 to 16.47728, saving model to keras_model_162InConvWeight/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00156: val_loss improved from 16.47971 to 16.47728, saving model to keras_model_162InConvWeight/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00156: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00156: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 157/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.9358 - mae: 14.1411 - val_loss: 16.4453 - val_mae: 13.6512\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00157: val_loss improved from 16.47728 to 16.44530, saving model to keras_model_162InConvWeight/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00157: val_loss improved from 16.47728 to 16.44530, saving model to keras_model_162InConvWeight/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00157: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00157: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 158/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.9144 - mae: 14.1213 - val_loss: 16.4165 - val_mae: 13.6244\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00158: val_loss improved from 16.44530 to 16.41651, saving model to keras_model_162InConvWeight/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00158: val_loss improved from 16.44530 to 16.41651, saving model to keras_model_162InConvWeight/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00158: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00158: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 159/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.9764 - mae: 14.1848 - val_loss: 16.4020 - val_mae: 13.6112\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00159: val_loss improved from 16.41651 to 16.40195, saving model to keras_model_162InConvWeight/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00159: val_loss improved from 16.41651 to 16.40195, saving model to keras_model_162InConvWeight/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00159: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00159: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 160/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.9533 - mae: 14.1629 - val_loss: 16.4004 - val_mae: 13.6110\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00160: val_loss improved from 16.40195 to 16.40044, saving model to keras_model_162InConvWeight/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00160: val_loss improved from 16.40195 to 16.40044, saving model to keras_model_162InConvWeight/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00160: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00160: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00160: saving model to keras_model_162InConvWeight/KERAS_check_model_epoch160.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 161/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.9744 - mae: 14.1853 - val_loss: 16.4325 - val_mae: 13.6443\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 16.40044\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 16.40044\n",
      "\n",
      "Epoch 00161: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00161: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 162/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.9768 - mae: 14.1887 - val_loss: 16.5085 - val_mae: 13.7214\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 16.40044\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 16.40044\n",
      "\n",
      "Epoch 00162: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00162: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 163/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.0111 - mae: 14.2244 - val_loss: 16.5917 - val_mae: 13.8056\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 16.40044\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 16.40044\n",
      "\n",
      "Epoch 00163: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00163: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 164/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.9910 - mae: 14.2059 - val_loss: 16.4591 - val_mae: 13.6750\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 16.40044\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 16.40044\n",
      "\n",
      "Epoch 00164: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00164: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 165/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.9324 - mae: 14.1488 - val_loss: 16.6356 - val_mae: 13.8530\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 16.40044\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 16.40044\n",
      "\n",
      "Epoch 00165: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00165: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 166/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.9682 - mae: 14.1860 - val_loss: 16.6528 - val_mae: 13.8718\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 16.40044\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 16.40044\n",
      "\n",
      "Epoch 00166: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00166: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 167/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8984 - mae: 14.1177 - val_loss: 16.5455 - val_mae: 13.7655\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 16.40044\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 16.40044\n",
      "\n",
      "Epoch 00167: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00167: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 168/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 20s 2s/step - loss: 16.9592 - mae: 14.1794 - val_loss: 16.4818 - val_mae: 13.7032\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 16.40044\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 16.40044\n",
      "\n",
      "Epoch 00168: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00168: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 169/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8767 - mae: 14.0987 - val_loss: 16.6612 - val_mae: 13.8835\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 16.40044\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 16.40044\n",
      "\n",
      "Epoch 00169: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00169: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 170/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.9202 - mae: 14.1436 - val_loss: 16.4595 - val_mae: 13.6836\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 16.40044\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 16.40044\n",
      "\n",
      "Epoch 00170: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00170: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00170: saving model to keras_model_162InConvWeight/KERAS_check_model_epoch170.h5\n",
      "\n",
      "Epoch 00170: ReduceLROnPlateau reducing learning rate to 2.3437500203726813e-05.\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 171/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.9130 - mae: 14.1377 - val_loss: 16.4139 - val_mae: 13.6392\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 16.40044\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 16.40044\n",
      "\n",
      "Epoch 00171: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00171: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 172/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.9868 - mae: 14.2124 - val_loss: 16.4065 - val_mae: 13.6327\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 16.40044\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 16.40044\n",
      "\n",
      "Epoch 00172: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00172: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 173/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8534 - mae: 14.0799 - val_loss: 16.4103 - val_mae: 13.6373\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 16.40044\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 16.40044\n",
      "\n",
      "Epoch 00173: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00173: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 174/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.9029 - mae: 14.1302 - val_loss: 16.4820 - val_mae: 13.7096\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 16.40044\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 16.40044\n",
      "\n",
      "Epoch 00174: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00174: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 175/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8433 - mae: 14.0713 - val_loss: 16.4969 - val_mae: 13.7253\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 16.40044\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 16.40044\n",
      "\n",
      "Epoch 00175: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00175: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 176/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.9013 - mae: 14.1300 - val_loss: 16.4760 - val_mae: 13.7053\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 16.40044\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 16.40044\n",
      "\n",
      "Epoch 00176: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00176: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 177/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.9025 - mae: 14.1317 - val_loss: 16.4846 - val_mae: 13.7138\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 16.40044\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 16.40044\n",
      "\n",
      "Epoch 00177: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00177: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 178/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.0029 - mae: 14.2328 - val_loss: 16.3859 - val_mae: 13.6166\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00178: val_loss improved from 16.40044 to 16.38593, saving model to keras_model_162InConvWeight/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00178: val_loss improved from 16.40044 to 16.38593, saving model to keras_model_162InConvWeight/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00178: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00178: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 179/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.9388 - mae: 14.1697 - val_loss: 16.3320 - val_mae: 13.5631\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00179: val_loss improved from 16.38593 to 16.33197, saving model to keras_model_162InConvWeight/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00179: val_loss improved from 16.38593 to 16.33197, saving model to keras_model_162InConvWeight/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00179: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00179: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 180/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8978 - mae: 14.1293 - val_loss: 16.3905 - val_mae: 13.6224\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 16.33197\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 16.33197\n",
      "\n",
      "Epoch 00180: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00180: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00180: saving model to keras_model_162InConvWeight/KERAS_check_model_epoch180.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 181/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8562 - mae: 14.0884 - val_loss: 16.3624 - val_mae: 13.5950\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 16.33197\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 16.33197\n",
      "\n",
      "Epoch 00181: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00181: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 182/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8423 - mae: 14.0751 - val_loss: 16.4232 - val_mae: 13.6565\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 16.33197\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 16.33197\n",
      "\n",
      "Epoch 00182: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00182: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 183/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 20s 2s/step - loss: 16.8732 - mae: 14.1069 - val_loss: 16.4590 - val_mae: 13.6930\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 16.33197\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 16.33197\n",
      "\n",
      "Epoch 00183: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00183: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 184/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8800 - mae: 14.1144 - val_loss: 16.4211 - val_mae: 13.6561\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 16.33197\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 16.33197\n",
      "\n",
      "Epoch 00184: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00184: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 185/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.9094 - mae: 14.1447 - val_loss: 16.4082 - val_mae: 13.6438\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 16.33197\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 16.33197\n",
      "\n",
      "Epoch 00185: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00185: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 186/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 17.0056 - mae: 14.2415 - val_loss: 16.4646 - val_mae: 13.7010\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 16.33197\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 16.33197\n",
      "\n",
      "Epoch 00186: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00186: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 187/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.9259 - mae: 14.1625 - val_loss: 16.5345 - val_mae: 13.7714\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 16.33197\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 16.33197\n",
      "\n",
      "Epoch 00187: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00187: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 188/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.9161 - mae: 14.1534 - val_loss: 16.5307 - val_mae: 13.7686\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 16.33197\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 16.33197\n",
      "\n",
      "Epoch 00188: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00188: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 189/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.9659 - mae: 14.2041 - val_loss: 16.3629 - val_mae: 13.6013\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 16.33197\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 16.33197\n",
      "\n",
      "Epoch 00189: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00189: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00189: ReduceLROnPlateau reducing learning rate to 1.1718750101863407e-05.\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 190/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8114 - mae: 14.0501 - val_loss: 16.3483 - val_mae: 13.5873\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 16.33197\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 16.33197\n",
      "\n",
      "Epoch 00190: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00190: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00190: saving model to keras_model_162InConvWeight/KERAS_check_model_epoch190.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 191/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.9554 - mae: 14.1947 - val_loss: 16.3082 - val_mae: 13.5477\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00191: val_loss improved from 16.33197 to 16.30824, saving model to keras_model_162InConvWeight/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00191: val_loss improved from 16.33197 to 16.30824, saving model to keras_model_162InConvWeight/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00191: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00191: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 192/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.7694 - mae: 14.0090 - val_loss: 16.3271 - val_mae: 13.5669\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 16.30824\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 16.30824\n",
      "\n",
      "Epoch 00192: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00192: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 193/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.9164 - mae: 14.1565 - val_loss: 16.3229 - val_mae: 13.5631\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 16.30824\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 16.30824\n",
      "\n",
      "Epoch 00193: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00193: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 194/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.9587 - mae: 14.1990 - val_loss: 16.3203 - val_mae: 13.5608\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 16.30824\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 16.30824\n",
      "\n",
      "Epoch 00194: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00194: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 195/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8246 - mae: 14.0654 - val_loss: 16.3343 - val_mae: 13.5753\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 16.30824\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 16.30824\n",
      "\n",
      "Epoch 00195: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00195: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 196/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.9664 - mae: 14.2076 - val_loss: 16.3556 - val_mae: 13.5970\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 16.30824\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 16.30824\n",
      "\n",
      "Epoch 00196: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00196: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 197/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8673 - mae: 14.1087 - val_loss: 16.3301 - val_mae: 13.5716\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 16.30824\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 16.30824\n",
      "\n",
      "Epoch 00197: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00197: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 198/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.9890 - mae: 14.2308 - val_loss: 16.3031 - val_mae: 13.5452\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00198: val_loss improved from 16.30824 to 16.30314, saving model to keras_model_162InConvWeight/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00198: val_loss improved from 16.30824 to 16.30314, saving model to keras_model_162InConvWeight/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00198: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00198: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 199/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.9199 - mae: 14.1621 - val_loss: 16.2916 - val_mae: 13.5340\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00199: val_loss improved from 16.30314 to 16.29161, saving model to keras_model_162InConvWeight/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00199: val_loss improved from 16.30314 to 16.29161, saving model to keras_model_162InConvWeight/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00199: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00199: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 200/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8442 - mae: 14.0868 - val_loss: 16.2887 - val_mae: 13.5314\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00200: val_loss improved from 16.29161 to 16.28867, saving model to keras_model_162InConvWeight/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00200: val_loss improved from 16.29161 to 16.28867, saving model to keras_model_162InConvWeight/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00200: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00200: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00200: saving model to keras_model_162InConvWeight/KERAS_check_model_epoch200.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 201/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8355 - mae: 14.0781 - val_loss: 16.3109 - val_mae: 13.5537\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00201: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00201: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 202/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8779 - mae: 14.1210 - val_loss: 16.3007 - val_mae: 13.5442\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00202: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00202: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 203/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8271 - mae: 14.0707 - val_loss: 16.3176 - val_mae: 13.5614\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00203: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00203: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 204/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8565 - mae: 14.1005 - val_loss: 16.3202 - val_mae: 13.5643\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00204: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00204: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 205/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8699 - mae: 14.1143 - val_loss: 16.3238 - val_mae: 13.5683\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00205: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00205: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 206/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8377 - mae: 14.0824 - val_loss: 16.3406 - val_mae: 13.5857\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00206: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00206: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 207/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8821 - mae: 14.1272 - val_loss: 16.2994 - val_mae: 13.5447\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00207: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00207: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 208/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8418 - mae: 14.0873 - val_loss: 16.5132 - val_mae: 13.7590\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00208: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00208: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 209/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8969 - mae: 14.1428 - val_loss: 16.4984 - val_mae: 13.7445\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00209: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00209: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 210/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8013 - mae: 14.0475 - val_loss: 16.4762 - val_mae: 13.7226\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00210: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00210: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00210: saving model to keras_model_162InConvWeight/KERAS_check_model_epoch210.h5\n",
      "\n",
      "Epoch 00210: ReduceLROnPlateau reducing learning rate to 5.859375050931703e-06.\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 211/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8885 - mae: 14.1350 - val_loss: 16.4859 - val_mae: 13.7324\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00211: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00211: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 212/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8532 - mae: 14.0999 - val_loss: 16.5172 - val_mae: 13.7639\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00212: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00212: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 213/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.7725 - mae: 14.0194 - val_loss: 16.5570 - val_mae: 13.8040\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00213: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00213: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 214/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 20s 2s/step - loss: 16.8245 - mae: 14.0717 - val_loss: 16.5397 - val_mae: 13.7870\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00214: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00214: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 215/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8167 - mae: 14.0641 - val_loss: 16.5809 - val_mae: 13.8284\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00215: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00215: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 216/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.7844 - mae: 14.0320 - val_loss: 16.5700 - val_mae: 13.8176\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00216: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00216: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 217/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.9375 - mae: 14.1853 - val_loss: 16.5084 - val_mae: 13.7562\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00217: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00217: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 218/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8899 - mae: 14.1378 - val_loss: 16.4929 - val_mae: 13.7409\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00218: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00218: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 219/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.9177 - mae: 14.1659 - val_loss: 16.4993 - val_mae: 13.7476\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00219: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00219: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 220/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.7592 - mae: 14.0075 - val_loss: 16.4287 - val_mae: 13.6772\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00220: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00220: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00220: saving model to keras_model_162InConvWeight/KERAS_check_model_epoch220.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 221/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8391 - mae: 14.0876 - val_loss: 16.4399 - val_mae: 13.6885\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00221: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00221: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00221: ReduceLROnPlateau reducing learning rate to 2.9296875254658516e-06.\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 222/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8064 - mae: 14.0551 - val_loss: 16.4373 - val_mae: 13.6860\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00222: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00222: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 223/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8745 - mae: 14.1233 - val_loss: 16.4361 - val_mae: 13.6850\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00223: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00223: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 224/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.7543 - mae: 14.0033 - val_loss: 16.4451 - val_mae: 13.6940\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00224: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00224: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 225/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.7898 - mae: 14.0388 - val_loss: 16.4187 - val_mae: 13.6677\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00225: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00225: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 226/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8801 - mae: 14.1292 - val_loss: 16.3965 - val_mae: 13.6456\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00226: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00226: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 227/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8666 - mae: 14.1158 - val_loss: 16.3894 - val_mae: 13.6387\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00227: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00227: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 228/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8718 - mae: 14.1211 - val_loss: 16.4211 - val_mae: 13.6705\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00228: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00228: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 229/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.9176 - mae: 14.1670 - val_loss: 16.4696 - val_mae: 13.7191\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00229: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00229: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 230/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 20s 2s/step - loss: 16.8730 - mae: 14.1225 - val_loss: 16.4387 - val_mae: 13.6882\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00230: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00230: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00230: saving model to keras_model_162InConvWeight/KERAS_check_model_epoch230.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 231/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8698 - mae: 14.1193 - val_loss: 16.4630 - val_mae: 13.7126\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00231: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00231: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 232/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8091 - mae: 14.0587 - val_loss: 16.4362 - val_mae: 13.6859\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00232: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00232: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00232: ReduceLROnPlateau reducing learning rate to 1.4648437627329258e-06.\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 233/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8492 - mae: 14.0989 - val_loss: 16.3971 - val_mae: 13.6468\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00233: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00233: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 234/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8077 - mae: 14.0575 - val_loss: 16.3575 - val_mae: 13.6073\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00234: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00234: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 235/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8072 - mae: 14.0571 - val_loss: 16.4090 - val_mae: 13.6588\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00235: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00235: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 236/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8219 - mae: 14.0718 - val_loss: 16.4804 - val_mae: 13.7303\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00236: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00236: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 237/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8103 - mae: 14.0602 - val_loss: 16.4591 - val_mae: 13.7091\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00237: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00237: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 238/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8232 - mae: 14.0731 - val_loss: 16.3798 - val_mae: 13.6298\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00238: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00238: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 239/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.9057 - mae: 14.1558 - val_loss: 16.3582 - val_mae: 13.6082\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00239: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00239: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 240/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.9777 - mae: 14.2278 - val_loss: 16.4514 - val_mae: 13.7015\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00240: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00240: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00240: saving model to keras_model_162InConvWeight/KERAS_check_model_epoch240.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 241/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.7301 - mae: 13.9802 - val_loss: 16.4343 - val_mae: 13.6844\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00241: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00241: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 242/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8436 - mae: 14.0938 - val_loss: 16.3711 - val_mae: 13.6213\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00242: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00242: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 243/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.7585 - mae: 14.0088 - val_loss: 16.3461 - val_mae: 13.5963\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00243: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00243: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00243: ReduceLROnPlateau reducing learning rate to 7.324218813664629e-07.\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 244/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8675 - mae: 14.1178 - val_loss: 16.3941 - val_mae: 13.6444\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00244: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00244: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 245/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.7963 - mae: 14.0466 - val_loss: 16.3818 - val_mae: 13.6321\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00245: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00245: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 246/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 20s 2s/step - loss: 16.7679 - mae: 14.0182 - val_loss: 16.3827 - val_mae: 13.6330\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00246: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00246: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 247/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8266 - mae: 14.0770 - val_loss: 16.3252 - val_mae: 13.5756\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00247: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00247: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 248/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8931 - mae: 14.1435 - val_loss: 16.3463 - val_mae: 13.5967\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00248: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00248: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 249/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8474 - mae: 14.0978 - val_loss: 16.3597 - val_mae: 13.6102\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00249: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00249: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 250/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8196 - mae: 14.0701 - val_loss: 16.3816 - val_mae: 13.6321\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00250: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00250: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00250: saving model to keras_model_162InConvWeight/KERAS_check_model_epoch250.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 251/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8436 - mae: 14.0941 - val_loss: 16.3626 - val_mae: 13.6130\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00251: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00251: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 252/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8609 - mae: 14.1114 - val_loss: 16.3643 - val_mae: 13.6149\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00252: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00252: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 253/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8806 - mae: 14.1311 - val_loss: 16.3326 - val_mae: 13.5831\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00253: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00253: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 254/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8185 - mae: 14.0691 - val_loss: 16.3165 - val_mae: 13.5671\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00254: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00254: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00254: ReduceLROnPlateau reducing learning rate to 3.6621094068323146e-07.\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 255/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.7805 - mae: 14.0310 - val_loss: 16.3117 - val_mae: 13.5623\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00255: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00255: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 256/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8973 - mae: 14.1478 - val_loss: 16.3498 - val_mae: 13.6004\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00256: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00256: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 257/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.9056 - mae: 14.1562 - val_loss: 16.3489 - val_mae: 13.5995\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00257: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00257: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 258/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.7707 - mae: 14.0213 - val_loss: 16.3073 - val_mae: 13.5580\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00258: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00258: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 259/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8564 - mae: 14.1070 - val_loss: 16.3550 - val_mae: 13.6057\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00259: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00259: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 260/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.9430 - mae: 14.1936 - val_loss: 16.3002 - val_mae: 13.5508\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00260: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00260: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00260: saving model to keras_model_162InConvWeight/KERAS_check_model_epoch260.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 261/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.7260 - mae: 13.9766 - val_loss: 16.3900 - val_mae: 13.6407\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00261: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00261: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 262/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 20s 2s/step - loss: 16.8426 - mae: 14.0933 - val_loss: 16.3560 - val_mae: 13.6067\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00262: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00262: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 263/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8370 - mae: 14.0877 - val_loss: 16.3023 - val_mae: 13.5530\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00263: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00263: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 264/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8341 - mae: 14.0848 - val_loss: 16.3041 - val_mae: 13.5548\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00264: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00264: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 265/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8967 - mae: 14.1474 - val_loss: 16.3056 - val_mae: 13.5563\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00265: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00265: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00265: ReduceLROnPlateau reducing learning rate to 1.8310547034161573e-07.\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 266/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8692 - mae: 14.1199 - val_loss: 16.3688 - val_mae: 13.6195\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00266: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00266: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 267/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8430 - mae: 14.0937 - val_loss: 16.3731 - val_mae: 13.6239\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00267: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00267: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 268/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8688 - mae: 14.1195 - val_loss: 16.3515 - val_mae: 13.6022\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00268: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00268: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 269/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.7826 - mae: 14.0334 - val_loss: 16.3652 - val_mae: 13.6159\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00269: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00269: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 270/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8436 - mae: 14.0944 - val_loss: 16.2996 - val_mae: 13.5503\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00270: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00270: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00270: saving model to keras_model_162InConvWeight/KERAS_check_model_epoch270.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 271/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8376 - mae: 14.0884 - val_loss: 16.3021 - val_mae: 13.5528\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00271: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00271: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 272/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.9177 - mae: 14.1684 - val_loss: 16.3175 - val_mae: 13.5682\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 16.28867\n",
      "\n",
      "Epoch 00272: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00272: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 273/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.7313 - mae: 13.9820 - val_loss: 16.2848 - val_mae: 13.5355\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00273: val_loss improved from 16.28867 to 16.28478, saving model to keras_model_162InConvWeight/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00273: val_loss improved from 16.28867 to 16.28478, saving model to keras_model_162InConvWeight/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00273: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00273: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 274/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.7907 - mae: 14.0414 - val_loss: 16.2884 - val_mae: 13.5392\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 16.28478\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 16.28478\n",
      "\n",
      "Epoch 00274: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00274: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 275/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8989 - mae: 14.1496 - val_loss: 16.2911 - val_mae: 13.5419\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 16.28478\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 16.28478\n",
      "\n",
      "Epoch 00275: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00275: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 276/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.7484 - mae: 13.9992 - val_loss: 16.2902 - val_mae: 13.5409\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 16.28478\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 16.28478\n",
      "\n",
      "Epoch 00276: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00276: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 277/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8467 - mae: 14.0975 - val_loss: 16.2688 - val_mae: 13.5196\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00277: val_loss improved from 16.28478 to 16.26881, saving model to keras_model_162InConvWeight/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00277: val_loss improved from 16.28478 to 16.26881, saving model to keras_model_162InConvWeight/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00277: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00277: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 278/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.9412 - mae: 14.1920 - val_loss: 16.2746 - val_mae: 13.5254\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 16.26881\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 16.26881\n",
      "\n",
      "Epoch 00278: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00278: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 279/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8426 - mae: 14.0934 - val_loss: 16.2717 - val_mae: 13.5225\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 16.26881\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 16.26881\n",
      "\n",
      "Epoch 00279: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00279: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 280/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.7854 - mae: 14.0362 - val_loss: 16.3635 - val_mae: 13.6143\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 16.26881\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 16.26881\n",
      "\n",
      "Epoch 00280: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00280: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00280: saving model to keras_model_162InConvWeight/KERAS_check_model_epoch280.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 281/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8673 - mae: 14.1181 - val_loss: 16.2861 - val_mae: 13.5369\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 16.26881\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 16.26881\n",
      "\n",
      "Epoch 00281: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00281: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 282/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.9269 - mae: 14.1777 - val_loss: 16.2904 - val_mae: 13.5412\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 16.26881\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 16.26881\n",
      "\n",
      "Epoch 00282: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00282: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 283/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8828 - mae: 14.1336 - val_loss: 16.2901 - val_mae: 13.5409\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 16.26881\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 16.26881\n",
      "\n",
      "Epoch 00283: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00283: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 284/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.7623 - mae: 14.0131 - val_loss: 16.3179 - val_mae: 13.5687\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 16.26881\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 16.26881\n",
      "\n",
      "Epoch 00284: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00284: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 285/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8314 - mae: 14.0823 - val_loss: 16.3377 - val_mae: 13.5886\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 16.26881\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 16.26881\n",
      "\n",
      "Epoch 00285: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00285: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 286/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8397 - mae: 14.0906 - val_loss: 16.3367 - val_mae: 13.5875\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 16.26881\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 16.26881\n",
      "\n",
      "Epoch 00286: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00286: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 287/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8330 - mae: 14.0838 - val_loss: 16.3832 - val_mae: 13.6340\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 16.26881\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 16.26881\n",
      "\n",
      "Epoch 00287: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00287: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00287: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 288/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8704 - mae: 14.1213 - val_loss: 16.3664 - val_mae: 13.6173\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 16.26881\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 16.26881\n",
      "\n",
      "Epoch 00288: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00288: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 289/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.7633 - mae: 14.0142 - val_loss: 16.3292 - val_mae: 13.5800\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 16.26881\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 16.26881\n",
      "\n",
      "Epoch 00289: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00289: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 290/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8913 - mae: 14.1421 - val_loss: 16.3296 - val_mae: 13.5805\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 16.26881\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 16.26881\n",
      "\n",
      "Epoch 00290: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00290: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00290: saving model to keras_model_162InConvWeight/KERAS_check_model_epoch290.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 291/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8328 - mae: 14.0837 - val_loss: 16.2852 - val_mae: 13.5360\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 16.26881\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 16.26881\n",
      "\n",
      "Epoch 00291: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00291: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 292/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.7676 - mae: 14.0185 - val_loss: 16.2921 - val_mae: 13.5429\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 16.26881\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 16.26881\n",
      "\n",
      "Epoch 00292: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00292: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 293/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.7802 - mae: 14.0311 - val_loss: 16.2985 - val_mae: 13.5494\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 16.26881\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 16.26881\n",
      "\n",
      "Epoch 00293: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00293: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 294/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 20s 2s/step - loss: 16.7952 - mae: 14.0461 - val_loss: 16.2876 - val_mae: 13.5385\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 16.26881\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 16.26881\n",
      "\n",
      "Epoch 00294: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00294: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 295/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8349 - mae: 14.0858 - val_loss: 16.2809 - val_mae: 13.5317\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 16.26881\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 16.26881\n",
      "\n",
      "Epoch 00295: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00295: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 296/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8489 - mae: 14.0998 - val_loss: 16.2948 - val_mae: 13.5457\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 16.26881\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 16.26881\n",
      "\n",
      "Epoch 00296: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00296: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 297/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.9492 - mae: 14.2001 - val_loss: 16.2925 - val_mae: 13.5434\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 16.26881\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 16.26881\n",
      "\n",
      "Epoch 00297: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00297: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 298/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.7998 - mae: 14.0507 - val_loss: 16.3379 - val_mae: 13.5887\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 16.26881\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 16.26881\n",
      "\n",
      "Epoch 00298: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00298: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 299/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.8333 - mae: 14.0842 - val_loss: 16.3445 - val_mae: 13.5954\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 16.26881\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 16.26881\n",
      "\n",
      "Epoch 00299: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00299: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "Epoch 300/300\n",
      "9/9 [==============================] - 20s 2s/step - loss: 16.9152 - mae: 14.1661 - val_loss: 16.3402 - val_mae: 13.5911\n",
      "\n",
      "***callbacks***\n",
      "saving losses to keras_model_162InConvWeight/losses.log\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 16.26881\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 16.26881\n",
      "\n",
      "Epoch 00300: saving model to keras_model_162InConvWeight/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00300: saving model to keras_model_162InConvWeight/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00300: saving model to keras_model_162InConvWeight/KERAS_check_model_epoch300.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train = True\n",
    "if train:\n",
    "    nadam = Nadam(lr=0.001)\n",
    "    adam = Adam(learning_rate=3E-3, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=True)\n",
    "    model.compile(optimizer=adam, loss=['MeanAbsoluteError'], metrics=['mae'])\n",
    "    callbacks = all_callbacks(stop_patience = 1000,\n",
    "                              lr_factor = 0.5,\n",
    "                              lr_patience = 10,\n",
    "                              lr_epsilon = 0.000001,\n",
    "                              lr_cooldown = 2,\n",
    "                              lr_minimum = 0.0000001,\n",
    "                              outputDir = 'keras_model_162InConvWeight')\n",
    "    #callbacks = [tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=0),\n",
    "    #              TensorBoard(log_dir=\"model_5/logs\", profile_batch = 100000000)]\n",
    "    #clbks = TensorBoard(log_dir=\"keras_model_v6/logs\", profile_batch = 100000000)\n",
    "    #callbacks.callbacks.append(clbks)\n",
    "    #callbacks.callbacks.append(pruning_callbacks.UpdatePruningStep())\n",
    "    \n",
    "    model.fit(x_train_em_barrel, y_train_targets, batch_size=1024,\n",
    "              epochs=300, validation_split=0.1, shuffle=True,\n",
    "              callbacks = callbacks.callbacks)\n",
    "    # Save the model again but with the pruning 'stripped' to use the regular layer types\n",
    "    #model = strip_pruning(model)\n",
    "    model.save('keras_model_162InConvWeight/KERAS_check_best_model.h5')\n",
    "else:\n",
    "    from tensorflow.keras.models import load_model\n",
    "    from qkeras.utils import _add_supported_quantized_objects\n",
    "    co = {}\n",
    "    _add_supported_quantized_objects(co)\n",
    "    model = load_model('model_4/KERAS_check_best_model.h5', custom_objects=co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "a6568042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max 6.0\n",
      "min -26.0\n",
      "max 5.0\n",
      "min -22.0\n",
      "max 5.0\n",
      "min -23.0\n",
      "max 5.0\n",
      "min -23.0\n",
      "max 5.0\n",
      "min -23.0\n",
      "max 4.0\n",
      "min -22.0\n",
      "max 4.0\n",
      "min -23.0\n",
      "max 4.0\n",
      "min -21.0\n",
      "max 5.0\n",
      "min -24.0\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "def show_bit_range(output_pred):\n",
    "    min_integer_bit = np.ceil(np.log2(np.max(output_pred)))\n",
    "    min_fraction_bit = np.floor(np.log2(np.min(output_pred[output_pred>0])))\n",
    "    print('max',min_integer_bit) \n",
    "    print('min',min_fraction_bit)\n",
    "\n",
    "conv_model = Model(inputs=model.input, outputs=model.get_layer('conv2d_batchnorm').output)\n",
    "y_conv_0 = conv_model.predict(x_test_em_barrel)\n",
    "conv_model = Model(inputs=model.input, outputs=model.get_layer('conv2d_batchnorm_1').output)\n",
    "y_conv_1 = conv_model.predict(x_test_em_barrel)\n",
    "conv_model = Model(inputs=model.input, outputs=model.get_layer('conv2d_batchnorm_2').output)\n",
    "y_conv_2 = conv_model.predict(x_test_em_barrel)\n",
    "conv_model = Model(inputs=model.input, outputs=model.get_layer('conv2d_batchnorm_3').output)\n",
    "y_conv_3 = conv_model.predict(x_test_em_barrel)\n",
    "conv_model = Model(inputs=model.input, outputs=model.get_layer('conv2d_batchnorm_4').output)\n",
    "y_conv_4 = conv_model.predict(x_test_em_barrel)\n",
    "conv_model = Model(inputs=model.input, outputs=model.get_layer('conv2d_batchnorm_5').output)\n",
    "y_conv_5 = conv_model.predict(x_test_em_barrel)\n",
    "conv_model = Model(inputs=model.input, outputs=model.get_layer('conv2d_batchnorm_6').output)\n",
    "y_conv_6 = conv_model.predict(x_test_em_barrel)\n",
    "conv_model = Model(inputs=model.input, outputs=model.get_layer('conv2d_batchnorm_7').output)\n",
    "y_conv_7 = conv_model.predict(x_test_em_barrel)\n",
    "conv_model = Model(inputs=model.input, outputs=model.get_layer('conv2d_batchnorm_8').output)\n",
    "y_conv_8 = conv_model.predict(x_test_em_barrel)\n",
    "\n",
    "show_bit_range(y_conv_0)\n",
    "show_bit_range(y_conv_1)\n",
    "show_bit_range(y_conv_2)\n",
    "show_bit_range(y_conv_3)\n",
    "show_bit_range(y_conv_4)\n",
    "show_bit_range(y_conv_5)\n",
    "show_bit_range(y_conv_6)\n",
    "show_bit_range(y_conv_7)\n",
    "show_bit_range(y_conv_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "5b90f6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_norm           is normal keras bn layer\n",
      "conv2d_batchnorm     f=16 quantized_bits(16,10,1,alpha='auto') quantized_bits(16,10,1,alpha='auto') \n",
      "conv2d_batchnorm_1   f=32 quantized_bits(16,10,1,alpha='auto') quantized_bits(16,10,1,alpha='auto') \n",
      "conv2d_batchnorm_2   f=32 quantized_bits(16,10,1,alpha='auto') quantized_bits(16,10,1,alpha='auto') \n",
      "conv2d_batchnorm_3   f=64 quantized_bits(16,10,1,alpha='auto') quantized_bits(16,10,1,alpha='auto') \n",
      "conv2d_batchnorm_4   f=64 quantized_bits(16,10,1,alpha='auto') quantized_bits(16,10,1,alpha='auto') \n",
      "conv2d_batchnorm_5   f=128 quantized_bits(16,10,1,alpha='auto') quantized_bits(16,10,1,alpha='auto') \n",
      "conv2d_batchnorm_6   f=128 quantized_bits(16,10,1,alpha='auto') quantized_bits(16,10,1,alpha='auto') \n",
      "conv2d_batchnorm_7   f=256 quantized_bits(16,10,1,alpha='auto') quantized_bits(16,10,1,alpha='auto') \n",
      "conv2d_batchnorm_8   f=256 quantized_bits(16,10,1,alpha='auto') quantized_bits(16,10,1,alpha='auto') \n",
      "dense                u=256 quantized_bits(16,10,1,alpha='auto') \n",
      "batch_norm_1         is normal keras bn layer\n",
      "dense_1              u=256 quantized_bits(16,10,1,alpha='auto') \n",
      "batch_norm_2         is normal keras bn layer\n",
      "dense_2              u=1 quantized_bits(16,10,1,alpha='auto') quantized_bits(16,10,1,alpha='auto') \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from qkeras.autoqkeras.utils import print_qmodel_summary\n",
    "print_qmodel_summary(model)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "e15ce3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from qkeras.utils import _add_supported_quantized_objects\n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import pruning_wrapper\n",
    "co = {}\n",
    "_add_supported_quantized_objects(co)\n",
    "#co['PruneLowMagnitude'] = pruning_wrapper.PruneLowMagnitude\n",
    "#print(pruning_wrapper.PruneLowMagnitude)\n",
    "model = load_model('./keras_model_1610/KERAS_check_best_model.h5', custom_objects=co)\n",
    "#model_75 = load_model('./keras_model_v7/KERAS_check_best_model.h5', custom_objects=co)\n",
    "#model_30 = load_model('./keras_model_0.3_166/KERAS_check_best_model.h5', custom_objects=co)\n",
    "#model = load_model('keras_model_v9/KERAS_check_best_model.h5', custom_objects=co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "a5207c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of zeros = 0.0\n",
      "% of zeros = 0.0\n",
      "% of zeros = 0.0\n",
      "% of zeros = 0.0\n",
      "% of zeros = 0.0\n",
      "% of zeros = 0.0\n",
      "% of zeros = 0.0\n",
      "% of zeros = 0.0\n",
      "% of zeros = 0.0\n",
      "% of zeros = 0.0\n",
      "% of zeros = 0.0\n",
      "% of zeros = 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAa4AAAGbCAYAAACcQnSEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAARbElEQVR4nO3dX4jl51kH8O9jQioIXW1Takmy3ZQNxQjSwpheCFaw4sYwTSnFZqVaJWTJRUTwaqVeCWKqF0ppFAcb0opNjAF116RGGy3xItUkVUrSkGYNqdlYm7TVQVoxRl8vdqyT6f45s3NmfueZ8/nAkDnvOXPOw8tmvvP++b2/GmMEALr4jqkLAIDtEFwAtCK4AGhFcAHQiuACoJVLpy4gSS6//PJx6NChqcsAYIE8/vjjXx1jvGFr+0IE16FDh/LYY49NXQYAC6SqvnS2dlOFALQiuABoRXAB0IrgAqAVwQVAK5MGV1WtVtXa+vr6lGUA0MikwTXGODnGOHbgwIEpywCgEVOFALQiuABoRXAB0IrgAqAVwQVAK4ILgFYEFwCtCC4AWhFcALSyEDeShI4OHb//VY+fu/2GiSqB5WLEBUArDtkFoBWH7ALQiqlCAFoRXAC0IrgAaEVwAdCK4AKgFcEFQCuCC4BWBBcArQguAFoRXAC0IrgAaEVwAdCK4AKgFcEFQCuCC4BW3EgSgFbcSBKAVkwVAtCK4AKgFcEFQCuCC4BWBBcArQguAFoRXAC0IrgAaEVwAdCK4AKgFcEFQCuCC4BWLp26AOji0PH7Z37+udtv2O1yYGkJLjiPC4UVsPdMFQLQiuACoBXBBUAr1rhYOlvXrTZvpLCmBYtPcLH0diOszheOwM6YKgSgFSMu2AOu8YL5MeICoBXBBUArgguAVqxxsRQWeZu79S/YnrkHV1V9X5JfSHJ5kofGGL8z78+AzhY5RKGDmaYKq+rOqnqxqp7Y0n6kqp6uqlNVdTxJxhhPjTFuTfKTSX5o/iUDsMxmXeO6K8mRzQ1VdUmSO5Jcn+TaJEer6tqN596d5P4kD8ytUgDIjFOFY4yHq+rQlubrkpwaYzybJFV1T5Ibk3xhjHEiyYmquj/JJ8/2nlV1LMmxJDl48ODFVQ/nYDoO9q+drHFdkeT5TY9PJ3lHVf1IkvcmeU3OM+IaY6wlWUuSlZWVsYM6YN9wVBRc2Nw3Z4wxPpPkM/N+X7gQoyxYDjsJrheSXLXp8ZUbbbAnBBUsp50E16NJrqmqq3MmsG5K8lPbeYOqWk2yevjw4R2UAfuXa7zg2826Hf7uJI8keWtVna6qm8cYryS5LcmDSZ5Kcu8Y48ntfPgY4+QY49iBAwe2WzcAS2rWXYVHz9H+QGx5hz1h4wac4axCAFpxViGt2JABTDriqqrVqlpbX1+fsgwAGpk0uGzOAGC7TBWy0EwNAlvZnAFAK0Zc0NT5RqO2yrOfGXEB0MqkIy5HPsHucLEy+5ldhQC0YqoQgFYEFwCtCC4AWhFcALQiuABoxXZ4FoojnnaHOymzn9gOD0ArjnyCJePiZLqzxgVAK0ZcsOSsf9GN4GJyNmQA22GqEIBWJg2uqlqtqrX19fUpywCgkUmnCscYJ5OcXFlZuWXKOthbpgaBnbDGBXyLrfJ0YI0LgFaMuNgTpgeBeRFcwDm5xotFZKoQgFaMuICZ2LjBojDiAqAVwQVAK07OAKAVN5IEoBVThQC0Ylchu8IFx/ufa7yYiuBiboQVsBdMFQLQiuACoBXBBUArgguAVgQXAK3YVQjs2IV2lNouzzwZcQHQirMKAWjFWYUAtGKNi4vmpAxgCta4AGhFcAHQiqlCYNedb1rZVnm2y4gLgFYEFwCtmCpkW+wkBKZmxAVAK4ILgFYEFwCtCC4AWhFcALQiuABoRXAB0IrruDgv120Bi0ZwAZPa/MeRcwuZhTsgA9CKOyAD0IrNGQC0IrgAaEVwAdCKXYXAwth6+YVdhpyNERcArRhx8SouOAYWnREXAK0YcQELy6kanI0RFwCtCC4AWhFcALQiuABoRXAB0Ipdhbh2C2hFcC0hQQV0ZqoQgFYEFwCtCC4AWrHGBbRwvrVZx0EtF8EFtOc+XsvFVCEArQguAFoRXAC0IrgAaGVXNmdU1XuS3JDktUk+Nsb4i934HACWz8wjrqq6s6perKontrQfqaqnq+pUVR1PkjHGn4wxbklya5L3z7dkAJbZdkZcdyX5aJJP/F9DVV2S5I4kP5bkdJJHq+rEGOMLGy/55Y3nmZjzCYH9YuYR1xjj4SRf39J8XZJTY4xnxxgvJ7knyY11xoeTfGqM8bn5lQvAstvp5owrkjy/6fHpjbafT/KuJO+rqlvP9oNVdayqHquqx1566aUdlgHAstiVzRljjI8k+cgFXrOWZC1JVlZWxm7UAcD+s9MR1wtJrtr0+MqNNgDYFTsNrkeTXFNVV1fVZUluSnJi52UBwNltZzv83UkeSfLWqjpdVTePMV5JcluSB5M8leTeMcaT23jP1apaW19f327dACypmde4xhhHz9H+QJIHLubDxxgnk5xcWVm55WJ+HoDl48gnAFpxP659ygXHwH5lxAVAK5OOuKpqNcnq4cOHpywD2GfcEXl/m3TENcY4OcY4duDAgSnLAKARa1zAvrd5BGb01Z81LgBaEVwAtCK4AGhl0uBy5BMA2zXp5gxHPs2Xi46BZWCqEIBWBBcArQguAFoRXAC0IrgAaMV2eABaccguAK04ZBdYKm550p/gaswFx8AysjkDgFYEFwCtCC4AWpl0jauqVpOsHj58eMoyAM7KnZMXk+3wALRiqhCAVgQXAK0ILgBacQEywAYX9fdgxAVAK4ILgFYEFwCtCC4AWnFyxoJzCwaAV3NyBgCt2A4PLLVZt8Cb/Vgc1rgAaEVwAdCK4AKgFcEFQCuCC4BWBBcArQguAFoRXAC04gLkZtwvCFh2k464qmq1qtbW19enLAOARpxVCEAr1rgAaMUaF8AOOYB3bxlxAdCK4AKgFcEFQCuCC4BWbM4AuAgOA5iOERcArQguAFoRXAC0IrgAaEVwAdCK4AKgFcEFQCuu4wKYM4fu7i4jLgBacQdkAFpxB2QAWrHGtWCcfwZwfta4AGhFcAHQiuACoBXBBUArgguAVgQXAK3YDr9HNm9zd/wLLBf//8+XERcArQguAFoxVTgBJ0cDXDwjLgBaEVwAtGKqEGBBWEaYjREXAK0ILgBaMVW4S9xXC2B3GHEB0IrgAqAVwQVAK4ILgFYEFwCtCC4AWhFcALQy9+CqqrdU1ceq6r55vzcAzBRcVXVnVb1YVU9saT9SVU9X1amqOp4kY4xnxxg370axADDriOuuJEc2N1TVJUnuSHJ9kmuTHK2qa+daHQBsMVNwjTEeTvL1Lc3XJTm1McJ6Ock9SW6cc30A8Co7OavwiiTPb3p8Osk7qur1SX41ydur6pfGGL92th+uqmNJjiXJwYMHd1BGf841BJjd3A/ZHWN8LcmtM7xuLclakqysrIx51wHA/rSTXYUvJLlq0+MrN9oAYNfsJLgeTXJNVV1dVZcluSnJifmUBQBnN+t2+LuTPJLkrVV1uqpuHmO8kuS2JA8meSrJvWOMJ7fz4VW1WlVr6+vr260bgCU10xrXGOPoOdofSPLAxX74GONkkpMrKyu3XOx7ALBcHPkEQCuCC4BWBBcArcz9Oq7tqKrVJKuHDx+esgyAPbP1wIHnbr9hokr6mnTENcY4OcY4duDAgSnLAKARU4UAtCK4AGhFcAHQiuACoBW7CgEm5LZG22dXIQCtmCoEoBXBBUArgguAVgQXAK0ILgBasR1+mzZvXd16OKZtrcA8ne93yjIfzms7PACtmCoEoBXBBUArgguAVgQXAK0ILgBamTS4qmq1qtbW19enLAOARmyHB6AVU4UAtCK4AGhFcAHQiuACoBXBBUArgguAVgQXAK0ILgBacSNJgOaW7YaTTs4AoBVThQC0IrgAaEVwAdCK4AKgFcEFQCuCC4BWBBcArQguAFoRXAC0IrgAaGXS4Kqq1apaW19fn7IMABpxViEArZgqBKAVwQVAK4ILgFYEFwCtCC4AWhFcALQiuABoRXAB0IrgAqAVwQVAK4ILgFYEFwCtCC4AWhFcALQiuABoRXAB0EqNMab78KrVJKuHDx++5Zlnntnx+x06fv+3vn/u9htmfu5i3weguwv9PpzF1t+L83jPJKmqx8cYK1vb3QEZgFZMFQLQiuACoBXBBUArgguAVgQXAK0ILgBaEVwAtCK4AGhFcAHQiuACoBXBBUArgguAVgQXAK0ILgBaEVwAtCK4AGhFcAHQiuACoBXBBUArgguAVgQXAK0ILgBaEVwAtCK4AGjl0nm/YVV9V5LfTvJyks+MMf5g3p8BwPKaacRVVXdW1YtV9cSW9iNV9XRVnaqq4xvN701y3xjjliTvnnO9ACy5WacK70pyZHNDVV2S5I4k1ye5NsnRqro2yZVJnt942X/Pp0wAOGOm4BpjPJzk61uar0tyaozx7Bjj5ST3JLkxyemcCa+Z3x8AZrWTNa4r8v8jq+RMYL0jyUeSfLSqbkhy8lw/XFXHkhxLkoMHD+6gjLM7dPz+ubx2O+8D0M3m33HP3X7DzM9Nae6bM8YY30jyczO8bi3JWpKsrKyMedcBwP60k6m8F5JctenxlRttALBrdhJcjya5pqqurqrLktyU5MR8ygKAs5t1O/zdSR5J8taqOl1VN48xXklyW5IHkzyV5N4xxpPb+fCqWq2qtfX19e3WDcCSmmmNa4xx9BztDyR54GI/fIxxMsnJlZWVWy72PQBYLrarA9CK4AKgFcEFQCuTBpfNGQBs16TBNcY4OcY4duDAgSnLAKARU4UAtCK4AGhFcAHQiuACoBW7CgFoxa5CAFqpMaa/FVZVvZTkSxOWcHmSr074+R3oowvTR+enfy5MH73am8cYb9jauBDBNbWqemyMsTJ1HYtMH12YPjo//XNh+mg2NmcA0IrgAqAVwXXG2tQFNKCPLkwfnZ/+uTB9NANrXAC0YsQFQCuCC4BWljK4qup1VfWXVfXMxn+/5yyveVtVPVJVT1bV56vq/VPUOpVZ+mjjdX9eVf9WVX+21zVOoaqOVNXTVXWqqo6f5fnXVNUfbjz/t1V1aIIyJzVDH/1wVX2uql6pqvdNUePUZuijX6yqL2z87nmoqt48RZ2LaimDK8nxJA+NMa5J8tDG462+meRnxhjfn+RIkt+qqu/euxInN0sfJclvJPnpPatqQlV1SZI7klyf5NokR6vq2i0vuznJv44xDif5zSQf3tsqpzVjH/1Tkp9N8sm9rW4xzNhHf59kZYzxA0nuS/Lre1vlYlvW4Loxycc3vv94kvdsfcEY44tjjGc2vv/nJC8m+bYruPexC/ZRkowxHkry73tU09SuS3JqjPHsGOPlJPfkTD9ttrnf7kvyo1VVe1jj1C7YR2OM58YYn0/yP1MUuABm6aO/HmN8c+PhZ5Ncucc1LrRlDa43jjG+vPH9vyR54/leXFXXJbksyT/udmELZFt9tCSuSPL8psenN9rO+poxxitJ1pO8fk+qWwyz9NGy224f3ZzkU7taUTOXTl3AbqmqTyf53rM89aHND8YYo6rOeU1AVb0pye8n+eAYY1/9hTivPgJ2R1V9IMlKkndOXcsi2bfBNcZ417meq6qvVNWbxhhf3gimF8/xutcmuT/Jh8YYn92lUiczjz5aMi8kuWrT4ys32s72mtNVdWmSA0m+tjflLYRZ+mjZzdRHVfWunPkj8p1jjP/co9paWNapwhNJPrjx/QeT/OnWF1TVZUn+OMknxhj37WFti+KCfbSEHk1yTVVdvfHv46ac6afNNvfb+5L81Viuq/xn6aNld8E+qqq3J/ndJO8eY/ijcasxxtJ95cyaw0NJnkny6SSv22hfSfJ7G99/IMl/JfmHTV9vm7r2Reqjjcd/k+SlJP+RM3P1Pz517bvcLz+R5Is5s975oY22X8mZXzBJ8p1J/ijJqSR/l+QtU9e8gH30gxv/Vr6RM6PRJ6eueQH76NNJvrLpd8+JqWtepC9HPgHQyrJOFQLQlOACoBXBBUArgguAVgQXAK0ILgBaEVwAtPK/Xo7W5E3XKmwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAa4AAAGbCAYAAACcQnSEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAASaElEQVR4nO3dXYxlV3oW4PeLLQdpUBqSsULkn7SjtiwahBKp8NwRJAbRxulxFI0UNwQmyHJrkMwNNzQarrhy4AIYYQitxHKCwMZYAty4g8MYRubCAfcEFI1jOdNYDm4T4p4MlFASYUw+LroyUxT9c6rr55yvzvNIJdde59Q+n5fsemutvfba1d0BgCm+bdkFAMBuCC4ARhFcAIwiuAAYRXABMMqdyy4gST75yU/28ePHl10GACvkK1/5yte7++6d7SsRXMePH8+lS5eWXQYAK6SqfvV67aYKARhFcAEwiuACYBTBBcAogguAUQ4kuKrqE1V1qap+6CDOD8D6Wii4qurZqvqwqr66o/1UVb1TVZer6ty2l/5Kkhf3s1AASBYfcT2X5NT2hqq6I8kzSR5JcjLJmao6WVV/MskvJ/lwH+sEgCQL3oDc3a9X1fEdzQ8nudzd7yZJVb2Q5LEkvzfJJ3ItzH67qi529+/sPGdVnU1yNknuv//+2/4XAGC97GXnjHuSvL/t+EqST3X3U0lSVT+e5OvXC60k6e7zSc4nycbGhqdZArCQA9vyqbufO6hzA7C+9rKq8IMk9207vnerDQAOzF6C680kD1bVA1V1V5LHk7y8mxNU1emqOr+5ubmHMgBYJ4suh38+yRtJHqqqK1X1RHd/nOSpJK8meTvJi9391m4+vLsvdPfZY8eO7bZuANbUoqsKz9yg/WKSi/taEQDchC2fABhlJR4kCevk+LlX/p/j955+dEmVwExLHXFZnAHAbi01uCzOAGC3XOMCYBTBBcAogguAUSzOAGAUizMAGMVUIQCjCC4ARhFcAIwiuAAYxapCAEaxqhCAUUwVAjCK4AJgFMEFwCiCC4BRBBcAo1gOD8AolsMDMIqpQgBGEVwAjCK4ABhFcAEwiuACYBTBBcAo7uMCYBT3cQEwiqlCAEYRXACMIrgAGEVwATCK4AJgFMEFwCh3LrsAWHfHz73yze/fe/rRJVYCMxhxATCK4AJgFFs+ATCKLZ8AGMVUIQCjWFUIK2T7CsPEKkO4HsEFQwg1uEZwwQrbGVaLvibUOMoEFxxBRmccZRZnADCKEResAdtKcZQILjgEN7seBeyOqUIARjHign0yZTrOwg2mE1xwAEwNwsExVQjAKIILgFFMFcJtOirTgVOuzcHv8jwuAEZZ6oiruy8kubCxsfHkMuuARRyVERZMZ6oQbkJYweoRXMA3uceLCawqBGAUIy7ghqw4ZBUZcQEwiuACYBRThbCNVYSw+oy4ABhFcAEwiqlCYCHu8WJVGHEBMIrgAmAUwQXAKK5xAbfFNS+WxYgLgFGMuFh7bjqGWQQXa0dQwWymCgEYxYgL2BcegcJhMeICYBTBBcAo+x5cVfUHq+onq+qlqvqL+31+ANbbQte4qurZJD+U5MPu/sPb2k8l+TtJ7kjyU939dHe/neTzVfVtSX42yd/f/7KBVebmZA7SoiOu55Kc2t5QVXckeSbJI0lOJjlTVSe3XvtMkleSXNy3SgEgCwZXd7+e5Bs7mh9Ocrm73+3uj5K8kOSxrfe/3N2PJPmzNzpnVZ2tqktVdenq1au3Vz0Aa2cvy+HvSfL+tuMrST5VVX88yY8k+fbcZMTV3eeTnE+SjY2N3kMdcEtuOoajY9/v4+ruLyf58n6fFwCSvQXXB0nu23Z871YbLJ0RFhxdewmuN5M8WFUP5FpgPZ7kz+zmBFV1OsnpEydO7KEMYNXZVYP9tNDijKp6PskbSR6qqitV9UR3f5zkqSSvJnk7yYvd/dZuPry7L3T32WPHju22bgDW1EIjru4+c4P2i7HkHYBDZMsnAEYRXACMstTHmlicwX6yknAG20GxV0sNru6+kOTCxsbGk8usg5kEFawnD5IElspSeXbLNS4ARhFcAIyy1OCqqtNVdX5zc3OZZQAwyFKDy84ZAOyWqUIARrGqkFEsgQcEF7Ay3JzMIkwVAjCKLZ9YaaYGgZ2sKgRgFFOFAIxicQawsuxjyPUYcQEwiuACYBTBBcAoNtkFYBRPQAZGsKsGv8tUIQCjCC4ARnEfFyvFFk8syj1e68uIC4BRjLhYOqMsYDeMuAAYRXABMIobkAEYxfO4ABjFVCEAowguAEaxHB4Yzz6G68WIC4BRjLg4dG44BvbCiAuAUQQXAKMILgBGEVwAjLLUxRlVdTrJ6RMnTiyzDOCIsTz+aFtqcHX3hSQXNjY2nlxmHRw8KwmB/WKqEIBRBBcAowguAEYRXACMYssnDoTFGMBBMeICYBQjLuDI2z4D4J6u+Yy4ABhFcAEwiuACYBTBBcAogguAUQQXAKN4rAmwVjzyZD6PNWHf2C0DOAymCgEYRXABMIrgAmAUwQXAKIILgFEEFwCjCC4ARvE8Lm6b+7aAZRBcwFrzkMl5TBUCMIrgAmAUU4XsiutawLIZcQEwihEXN2WEBawaIy4ARhFcAIwiuAAYRXABMIrgAmAUwQXAKJbDA2zZefuHvQtXkxEXAKMcyIirqn44yaNJviPJT3f3zx/E5wCwfhYecVXVs1X1YVV9dUf7qap6p6ouV9W5JOnuf97dTyb5fJIf3d+SAVhnu5kqfC7Jqe0NVXVHkmeSPJLkZJIzVXVy21v+2tbrALAvFg6u7n49yTd2ND+c5HJ3v9vdHyV5Icljdc1PJPm57v7F652vqs5W1aWqunT16tXbrR+ANbPXxRn3JHl/2/GVrba/lOTTST5bVZ+/3g929/nu3ujujbvvvnuPZQCwLg5kcUZ3fzHJFw/i3ACst70G1wdJ7tt2fO9WG0N5jAl8y/b/H9zTtTr2OlX4ZpIHq+qBqroryeNJXl70h6vqdFWd39zc3GMZAKyL3SyHfz7JG0keqqorVfVEd3+c5KkkryZ5O8mL3f3Woufs7gvdffbYsWO7rRuANbXwVGF3n7lB+8UkF/etIgC4CVs+ATDKUoPLNS4AdmupweUaFwC7ZaoQgFEEFwCjCC4ARlnqE5Cr6nSS0ydOnFhmGWvPbhnAJBZnADCKqUIARhFcAIwiuAAYRXABMIotnwAYxapCAEZZ6n1cLIf7toDJBBfAAnb+wffe048uqRIszgBgFMEFwCiCC4BRLIcHYBTL4QEYxVQhAKMILgBGEVwAjOIG5DVhtwzgqDDiAmAUwQXAKIILgFGWeo2rqk4nOX3ixIlllgGwa9uvG9tw93C5ARmAUUwVAjCK4AJgFMEFwCiCC4BRBBcAo9jyCWCPdm6pZnn8wTLiAmAUwQXAKIILgFFs+XSE2IIGWAdLDa7uvpDkwsbGxpPLrOMo8vwt4KgyVQjAKIILgFHcxwVwiNzztXdGXACMIrgAGEVwATCK4AJgFMEFwChWFQLsMxsAHCwjLgBGEVwAjCK4ABhFcAEwiuACYJSlBldVna6q85ubm8ssA4BBlhpc3X2hu88eO3ZsmWUAMIipQgBGEVwAjCK4ABhFcAEwiuACYBTBBcAodocfxq7TwLoz4gJgFMEFwCiCC4BRBBcAowguAEYRXACMIrgAGEVwATCK4AJgFMEFwCiCC4BRBBcAowguAEaxOzzAEi36xIf3nn70gCuZY99HXFX1fVX101X10n6fGwAWCq6qeraqPqyqr+5oP1VV71TV5ao6lyTd/W53P3EQxQLAoiOu55Kc2t5QVXckeSbJI0lOJjlTVSf3tToA2GGh4Oru15N8Y0fzw0kub42wPkryQpLHFv3gqjpbVZeq6tLVq1cXLhiA9baXa1z3JHl/2/GVJPdU1XdV1U8m+YGq+qs3+uHuPt/dG929cffdd++hDADWyb6vKuzu30jy+f0+LwAkextxfZDkvm3H9261AcCB2UtwvZnkwap6oKruSvJ4kpd3c4KqOl1V5zc3N/dQBgDrZNHl8M8neSPJQ1V1paqe6O6PkzyV5NUkbyd5sbvf2s2Hd/eF7j577Nix3dYNwJpa6BpXd5+5QfvFJBf3tSIAuAl7FQIwiuACYJSlbrJbVaeTnD5x4sQyy1hpi27ACbAuljrisjgDgN0yVQjAKIILgFEEFwCjWJyxAizAAFicxRkAjGKqEIBRBBcAowguAEYRXACMYlUhwAA7Vx+/9/SjS6pk+awqBGAUU4UAjCK4ABhFcAEwiuACYBTBBcAolsMDHDHbl84fxWXzlsMDMIqpQgBGEVwAjCK4ABhFcAEwiuACYBTBBcAo7uPag5s9ZmA3rwHsxV5+p0y858t9XACMYqoQgFEEFwCjCC4ARhFcAIwiuAAYRXABMIrgAmAUwQXAKIILgFFs+XRIbPMErIKb/S662VZ1q8SWTwCMYqoQgFEEFwCjCC4ARhFcAIwiuAAYRXABMIrgAmAUwQXAKIILgFEEFwCjCC4ARhFcAIwiuAAYRXABMIrncd3ClOfTAFzPUXwWoOdxATCKqUIARhFcAIwiuAAYRXABMIrgAmAUwQXAKIILgFEEFwCjCC4ARhFcAIwiuAAYRXABMIrgAmAUwQXAKIILgFEEFwCjCC4ARhFcAIwiuAAYRXABMIrgAmCUO/f7hFX1iSR/L8lHSb7c3f9ovz8DgPW10Iirqp6tqg+r6qs72k9V1TtVdbmqzm01/0iSl7r7ySSf2ed6AVhzi04VPpfk1PaGqrojyTNJHklyMsmZqjqZ5N4k72+97f/sT5kAcM1CwdXdryf5xo7mh5Nc7u53u/ujJC8keSzJlVwLr4XPDwCL2ss1rnvyrZFVci2wPpXki0n+blU9muTCjX64qs4mOZsk999//x7K+Jbj51755vfvPf3oDV/baed7F/0MgGVZpd9FO2vZze/U27HvizO6+zeT/IUF3nc+yfkk2djY6P2uA4CjaS9TeR8kuW/b8b1bbQBwYPYSXG8mebCqHqiqu5I8nuTl/SkLAK5v0eXwzyd5I8lDVXWlqp7o7o+TPJXk1SRvJ3mxu9/azYdX1emqOr+5ubnbugFYUwtd4+ruMzdov5jk4u1+eHdfSHJhY2Pjyds9BwDrxXJ1AEYRXACMstTgco0LgN1aanB194XuPnvs2LFllgHAIKYKARhFcAEwiuACYBSLMwAYxeIMAEYxVQjAKIILgFGqe/mPwqqqq0l+ddl13KZPJvn6sotYcfro1vTRYvTTrR2lPvre7r57Z+NKBNdkVXWpuzeWXccq00e3po8Wo59ubR36yFQhAKMILgBGEVx7d37ZBQygj25NHy1GP93ake8j17gAGMWIC4BRBBcAowiuXaqq76yqf11VX9v65++/znu+v6reqKq3quqXqupHl1HrsizSR1vv+1dV9T+q6l8edo3LUlWnquqdqrpcVeeu8/q3V9U/2Xr931fV8SWUuVQL9NEfq6pfrKqPq+qzy6hxFSzQT3+5qn5563fQa1X1vcuo8yAIrt07l+S17n4wyWtbxzv9VpI/391/KMmpJH+7qn7f4ZW4dIv0UZL8zSR/7tCqWrKquiPJM0keSXIyyZmqOrnjbU8k+e/dfSLJ30ryE4db5XIt2Ef/JcmPJ/nHh1vd6liwn/5jko3u/iNJXkryNw63yoMjuHbvsSQ/s/X9zyT54Z1v6O5f6e6vbX3/X5N8mOT/u/v7CLtlHyVJd7+W5H8eUk2r4OEkl7v73e7+KMkLudZX223vu5eS/ImqqkOscdlu2Ufd/V53/1KS31lGgStikX76t939W1uHv5Dk3kOu8cAIrt377u7+ta3v/1uS777Zm6vq4SR3JfnPB13YCtlVH62Re5K8v+34ylbbdd/T3R8n2UzyXYdS3WpYpI/YfT89keTnDrSiQ3TnsgtYRVX1pSR/4DovfWH7QXd3Vd3wfoKq+p4k/zDJ57r7SP11uF99BBysqvqxJBtJfnDZtewXwXUd3f3pG71WVb9eVd/T3b+2FUwf3uB935HklSRf6O5fOKBSl2Y/+mgNfZDkvm3H9261Xe89V6rqziTHkvzG4ZS3EhbpIxbsp6r6dK79MfmD3f2/Dqm2A2eqcPdeTvK5re8/l+Rf7HxDVd2V5J8l+dnufukQa1sVt+yjNfVmkger6oGt/0Yez7W+2m573302yb/p9dolYJE+YoF+qqofSPIPknymu4/WH4/d7WsXX7l2veG1JF9L8qUk37nVvpHkp7a+/7Ek/zvJf9r29f3Lrn2V+mjr+N8luZrkt3Ntjv5PLbv2Q+ibP53kV3LtmucXttr+eq79ckmS35Pknya5nOQ/JPm+Zde8gn30R7f+e/nNXBuNvrXsmle0n76U5Ne3/Q56edk179eXLZ8AGMVUIQCjCC4ARhFcAIwiuAAYRXABMIrgAmAUwQXAKP8Xom5GEc7rDeUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "accum0 = 0\n",
    "accum1 = 0\n",
    "for layer in model.layers:\n",
    "    if layer.__class__.__name__ in ['QConv2DBatchnorm', 'QDense']:\n",
    "        w = layer.get_weights()[0]\n",
    "        h, b = np.histogram(w, bins=100)\n",
    "        plt.figure(figsize=(7,7))\n",
    "        plt.bar(b[:-1], h, width=b[1]-b[0])\n",
    "        plt.semilogy()\n",
    "        x = np.sum(w==0)\n",
    "        y = np.size(w)\n",
    "        accum0 = accum0 + x\n",
    "        accum1 = accum1 + y\n",
    "        print('% of zeros = {}'.format(accum0/accum1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "a0a73aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score unpruned: 14.29505443572998\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "#y_75 = model_75.predict(x_test_em_barrel)\n",
    "y_unp = model.predict(x_test_em_barrel)\n",
    "\n",
    "#print(\"Score 75% pruned: {}\".format(mean_absolute_error(y_test_targets, y_75)))\n",
    "#print(\"Score 30% pruned: {}\".format(mean_absolute_error(y_test_targets, y_30)))\n",
    "print(\"Score unpruned: {}\".format(mean_absolute_error(y_test_targets, y_unp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "f14058b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: em_barrel, layer type: Input\n",
      "Layer name: up_sampling, layer type: UpSampling2D\n",
      "Layer name: batch_norm, layer type: BatchNormalization\n",
      "Layer name: conv2d_batchnorm, layer type: QConv2DBatchnorm\n",
      "Layer name: leaky_relu, layer type: LeakyReLU\n",
      "Layer name: max_pooling2D, layer type: MaxPooling2D\n",
      "Layer name: conv2d_batchnorm_1, layer type: QConv2DBatchnorm\n",
      "Layer name: leaky_relu_1, layer type: LeakyReLU\n",
      "Layer name: conv2d_batchnorm_2, layer type: QConv2DBatchnorm\n",
      "Layer name: leaky_relu_2, layer type: LeakyReLU\n",
      "Layer name: max_pooling2D_1, layer type: MaxPooling2D\n",
      "Layer name: conv2d_batchnorm_3, layer type: QConv2DBatchnorm\n",
      "Layer name: leaky_relu_3, layer type: LeakyReLU\n",
      "Layer name: conv2d_batchnorm_4, layer type: QConv2DBatchnorm\n",
      "Layer name: leaky_relu_4, layer type: LeakyReLU\n",
      "Layer name: max_pooling2D_2, layer type: MaxPooling2D\n",
      "Layer name: conv2d_batchnorm_5, layer type: QConv2DBatchnorm\n",
      "Layer name: leaky_relu_5, layer type: LeakyReLU\n",
      "Layer name: conv2d_batchnorm_6, layer type: QConv2DBatchnorm\n",
      "Layer name: leaky_relu_6, layer type: LeakyReLU\n",
      "Layer name: max_pooling2D_3, layer type: MaxPooling2D\n",
      "Layer name: conv2d_batchnorm_7, layer type: QConv2DBatchnorm\n",
      "Layer name: leaky_relu_7, layer type: LeakyReLU\n",
      "Layer name: conv2d_batchnorm_8, layer type: QConv2DBatchnorm\n",
      "Layer name: leaky_relu_8, layer type: LeakyReLU\n",
      "Layer name: dense, layer type: QDense\n",
      "Layer name: batch_norm_1, layer type: BatchNormalization\n",
      "Layer name: leaky_relu_9, layer type: LeakyReLU\n",
      "Layer name: dense_1, layer type: QDense\n",
      "Layer name: batch_norm_2, layer type: BatchNormalization\n",
      "Layer name: leaky_relu_10, layer type: LeakyReLU\n",
      "Layer name: dense_2, layer type: QDense\n",
      "Layer name: activate, layer type: Activation\n",
      "-----------------------------------\n",
      "Model\n",
      "  Precision:         ap_fixed<16,6>\n",
      "  ReuseFactor:       1\n",
      "  Strategy:          Resource\n",
      "LayerName\n",
      "  em_barrel\n",
      "    Precision\n",
      "      result:        ap_fixed<16,6>\n",
      "  up_sampling\n",
      "    Precision\n",
      "      weight:        ap_fixed<16,6>\n",
      "      bias:          ap_fixed<16,6>\n",
      "      result:        ap_fixed<16,6>\n",
      "    ReuseFactor:     1\n",
      "  batch_norm\n",
      "    Precision\n",
      "      scale:         ap_fixed<16,6>\n",
      "      bias:          ap_fixed<16,6>\n",
      "    ReuseFactor:     1\n",
      "  conv2d_batchnorm\n",
      "    Precision\n",
      "      weight:        ap_fixed<16,11>\n",
      "      bias:          ap_fixed<16,11>\n",
      "    ReuseFactor:     1\n",
      "  leaky_relu\n",
      "    Precision:       ap_fixed<16,6>\n",
      "    ReuseFactor:     1\n",
      "    table_size:      1024\n",
      "    table_t:         ap_fixed<18,8>\n",
      "  max_pooling2D\n",
      "    Precision:       ap_fixed<16,6>\n",
      "  conv2d_batchnorm_1\n",
      "    Precision\n",
      "      weight:        ap_fixed<16,3>\n",
      "      bias:          ap_fixed<16,11>\n",
      "    ReuseFactor:     1\n",
      "  leaky_relu_1\n",
      "    Precision:       ap_fixed<16,6>\n",
      "    ReuseFactor:     1\n",
      "    table_size:      1024\n",
      "    table_t:         ap_fixed<18,8>\n",
      "  conv2d_batchnorm_2\n",
      "    Precision\n",
      "      weight:        ap_fixed<16,3>\n",
      "      bias:          ap_fixed<16,11>\n",
      "    ReuseFactor:     1\n",
      "  leaky_relu_2\n",
      "    Precision:       ap_fixed<16,6>\n",
      "    ReuseFactor:     1\n",
      "    table_size:      1024\n",
      "    table_t:         ap_fixed<18,8>\n",
      "  max_pooling2D_1\n",
      "    Precision:       ap_fixed<16,6>\n",
      "  conv2d_batchnorm_3\n",
      "    Precision\n",
      "      weight:        ap_fixed<16,3>\n",
      "      bias:          ap_fixed<16,11>\n",
      "    ReuseFactor:     1\n",
      "  leaky_relu_3\n",
      "    Precision:       ap_fixed<16,6>\n",
      "    ReuseFactor:     1\n",
      "    table_size:      1024\n",
      "    table_t:         ap_fixed<18,8>\n",
      "  conv2d_batchnorm_4\n",
      "    Precision\n",
      "      weight:        ap_fixed<16,3>\n",
      "      bias:          ap_fixed<16,11>\n",
      "    ReuseFactor:     1\n",
      "  leaky_relu_4\n",
      "    Precision:       ap_fixed<16,6>\n",
      "    ReuseFactor:     1\n",
      "    table_size:      1024\n",
      "    table_t:         ap_fixed<18,8>\n",
      "  max_pooling2D_2\n",
      "    Precision:       ap_fixed<16,6>\n",
      "  conv2d_batchnorm_5\n",
      "    Precision\n",
      "      weight:        ap_fixed<16,3>\n",
      "      bias:          ap_fixed<16,11>\n",
      "    ReuseFactor:     1\n",
      "  leaky_relu_5\n",
      "    Precision:       ap_fixed<16,6>\n",
      "    ReuseFactor:     1\n",
      "    table_size:      1024\n",
      "    table_t:         ap_fixed<18,8>\n",
      "  conv2d_batchnorm_6\n",
      "    Precision\n",
      "      weight:        ap_fixed<16,3>\n",
      "      bias:          ap_fixed<16,11>\n",
      "    ReuseFactor:     1\n",
      "  leaky_relu_6\n",
      "    Precision:       ap_fixed<16,6>\n",
      "    ReuseFactor:     1\n",
      "    table_size:      1024\n",
      "    table_t:         ap_fixed<18,8>\n",
      "  max_pooling2D_3\n",
      "    Precision:       ap_fixed<16,6>\n",
      "  conv2d_batchnorm_7\n",
      "    Precision\n",
      "      weight:        ap_fixed<16,3>\n",
      "      bias:          ap_fixed<16,11>\n",
      "    ReuseFactor:     1\n",
      "  leaky_relu_7\n",
      "    Precision:       ap_fixed<16,6>\n",
      "    ReuseFactor:     1\n",
      "    table_size:      1024\n",
      "    table_t:         ap_fixed<18,8>\n",
      "  conv2d_batchnorm_8\n",
      "    Precision\n",
      "      weight:        ap_fixed<16,3>\n",
      "      bias:          ap_fixed<16,11>\n",
      "    ReuseFactor:     1\n",
      "  leaky_relu_8\n",
      "    Precision:       ap_fixed<16,6>\n",
      "    ReuseFactor:     1\n",
      "    table_size:      1024\n",
      "    table_t:         ap_fixed<18,8>\n",
      "  dense\n",
      "    Precision\n",
      "      weight:        ap_fixed<16,11>\n",
      "    ReuseFactor:     1\n",
      "  batch_norm_1\n",
      "    Precision\n",
      "      scale:         ap_fixed<16,6>\n",
      "      bias:          ap_fixed<16,6>\n",
      "    ReuseFactor:     1\n",
      "  leaky_relu_9\n",
      "    Precision:       ap_fixed<16,6>\n",
      "    ReuseFactor:     1\n",
      "    table_size:      1024\n",
      "    table_t:         ap_fixed<18,8>\n",
      "  dense_1\n",
      "    Precision\n",
      "      weight:        ap_fixed<16,11>\n",
      "    ReuseFactor:     1\n",
      "  batch_norm_2\n",
      "    Precision\n",
      "      scale:         ap_fixed<16,6>\n",
      "      bias:          ap_fixed<16,6>\n",
      "    ReuseFactor:     1\n",
      "  leaky_relu_10\n",
      "    Precision:       ap_fixed<16,6>\n",
      "    ReuseFactor:     1\n",
      "    table_size:      1024\n",
      "    table_t:         ap_fixed<18,8>\n",
      "  dense_2\n",
      "    Precision\n",
      "      weight:        ap_fixed<16,11>\n",
      "      bias:          ap_fixed<16,11>\n",
      "    ReuseFactor:     1\n",
      "  activate\n",
      "    Precision:       ap_fixed<16,6>\n",
      "    ReuseFactor:     1\n",
      "    table_size:      1024\n",
      "    table_t:         ap_fixed<18,8>\n",
      "-----------------------------------\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: em_barrel, layer type: InputLayer, input shapes: [[None, 56, 11, 4]], output shape: [None, 56, 11, 4]\n",
      "Layer name: up_sampling, layer type: UpSampling2D, input shapes: [[None, 56, 11, 4]], output shape: [None, 56, 55, 4]\n",
      "Layer name: batch_norm, layer type: BatchNormalization, input shapes: [[None, 56, 55, 4]], output shape: [None, 56, 55, 4]\n",
      "Layer name: conv2d_batchnorm, layer type: QConv2DBatchnorm, input shapes: [[None, 56, 55, 4]], output shape: [None, 56, 55, 16]\n",
      "Layer name: leaky_relu, layer type: LeakyReLU, input shapes: [[None, 56, 55, 16]], output shape: [None, 56, 55, 16]\n",
      "Layer name: max_pooling2D, layer type: MaxPooling2D, input shapes: [[None, 56, 55, 16]], output shape: [None, 28, 27, 16]\n",
      "Layer name: conv2d_batchnorm_1, layer type: QConv2DBatchnorm, input shapes: [[None, 28, 27, 16]], output shape: [None, 28, 27, 32]\n",
      "Layer name: leaky_relu_1, layer type: LeakyReLU, input shapes: [[None, 28, 27, 32]], output shape: [None, 28, 27, 32]\n",
      "Layer name: conv2d_batchnorm_2, layer type: QConv2DBatchnorm, input shapes: [[None, 28, 27, 32]], output shape: [None, 28, 27, 32]\n",
      "Layer name: leaky_relu_2, layer type: LeakyReLU, input shapes: [[None, 28, 27, 32]], output shape: [None, 28, 27, 32]\n",
      "Layer name: max_pooling2D_1, layer type: MaxPooling2D, input shapes: [[None, 28, 27, 32]], output shape: [None, 14, 13, 32]\n",
      "Layer name: conv2d_batchnorm_3, layer type: QConv2DBatchnorm, input shapes: [[None, 14, 13, 32]], output shape: [None, 14, 13, 64]\n",
      "Layer name: leaky_relu_3, layer type: LeakyReLU, input shapes: [[None, 14, 13, 64]], output shape: [None, 14, 13, 64]\n",
      "Layer name: conv2d_batchnorm_4, layer type: QConv2DBatchnorm, input shapes: [[None, 14, 13, 64]], output shape: [None, 14, 13, 64]\n",
      "Layer name: leaky_relu_4, layer type: LeakyReLU, input shapes: [[None, 14, 13, 64]], output shape: [None, 14, 13, 64]\n",
      "Layer name: max_pooling2D_2, layer type: MaxPooling2D, input shapes: [[None, 14, 13, 64]], output shape: [None, 7, 6, 64]\n",
      "Layer name: conv2d_batchnorm_5, layer type: QConv2DBatchnorm, input shapes: [[None, 7, 6, 64]], output shape: [None, 7, 6, 128]\n",
      "Layer name: leaky_relu_5, layer type: LeakyReLU, input shapes: [[None, 7, 6, 128]], output shape: [None, 7, 6, 128]\n",
      "Layer name: conv2d_batchnorm_6, layer type: QConv2DBatchnorm, input shapes: [[None, 7, 6, 128]], output shape: [None, 7, 6, 128]\n",
      "Layer name: leaky_relu_6, layer type: LeakyReLU, input shapes: [[None, 7, 6, 128]], output shape: [None, 7, 6, 128]\n",
      "Layer name: max_pooling2D_3, layer type: MaxPooling2D, input shapes: [[None, 7, 6, 128]], output shape: [None, 3, 3, 128]\n",
      "Layer name: conv2d_batchnorm_7, layer type: QConv2DBatchnorm, input shapes: [[None, 3, 3, 128]], output shape: [None, 3, 3, 256]\n",
      "Layer name: leaky_relu_7, layer type: LeakyReLU, input shapes: [[None, 3, 3, 256]], output shape: [None, 3, 3, 256]\n",
      "Layer name: conv2d_batchnorm_8, layer type: QConv2DBatchnorm, input shapes: [[None, 3, 3, 256]], output shape: [None, 3, 3, 256]\n",
      "Layer name: leaky_relu_8, layer type: LeakyReLU, input shapes: [[None, 3, 3, 256]], output shape: [None, 3, 3, 256]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 3, 3, 256]], output shape: [None, 2304]\n",
      "Layer name: dense, layer type: QDense, input shapes: [[None, 2304]], output shape: [None, 256]\n",
      "Layer name: batch_norm_1, layer type: BatchNormalization, input shapes: [[None, 256]], output shape: [None, 256]\n",
      "Layer name: leaky_relu_9, layer type: LeakyReLU, input shapes: [[None, 256]], output shape: [None, 256]\n",
      "Layer name: dense_1, layer type: QDense, input shapes: [[None, 256]], output shape: [None, 256]\n",
      "Layer name: batch_norm_2, layer type: BatchNormalization, input shapes: [[None, 256]], output shape: [None, 256]\n",
      "Layer name: leaky_relu_10, layer type: LeakyReLU, input shapes: [[None, 256]], output shape: [None, 256]\n",
      "Layer name: dense_2, layer type: QDense, input shapes: [[None, 256]], output shape: [None, 1]\n",
      "Layer name: activate, layer type: Activation, input shapes: [[None, 1]], output shape: [None, 1]\n",
      "Creating HLS model\n",
      "WARNING: Invalid ReuseFactor=1 with \"Resource\" strategy in layer \"conv2d_batchnorm\". Using ReuseFactor=2 instead. Valid ReuseFactor(s): 2,4,5,10,20,25,50,100,200,400,800,1600.\n",
      "WARNING: Invalid ReuseFactor=1 with \"Resource\" strategy in layer \"conv2d_batchnorm_1\". Using ReuseFactor=2 instead. Valid ReuseFactor(s): 2,3,4,6,8,9,12,16,18,24,36,48,72,144,288,576,1152,2304,4608.\n",
      "WARNING: Invalid ReuseFactor=1 with \"Resource\" strategy in layer \"conv2d_batchnorm_2\". Using ReuseFactor=2 instead. Valid ReuseFactor(s): 2,3,4,6,8,9,12,16,18,24,32,36,48,72,96,144,288,576,1152,2304,4608,9216.\n",
      "WARNING: Invalid ReuseFactor=1 with \"Resource\" strategy in layer \"conv2d_batchnorm_3\". Using ReuseFactor=2 instead. Valid ReuseFactor(s): 2,3,4,6,8,9,12,16,18,24,32,36,48,72,96,144,288,576,1152,2304,4608,9216,18432.\n",
      "WARNING: Invalid ReuseFactor=1 with \"Resource\" strategy in layer \"conv2d_batchnorm_4\". Using ReuseFactor=2 instead. Valid ReuseFactor(s): 2,3,4,6,8,9,12,16,18,24,32,36,48,64,72,96,144,192,288,576,1152,2304,4608,9216,18432,36864.\n",
      "WARNING: Invalid ReuseFactor=1 with \"Resource\" strategy in layer \"conv2d_batchnorm_5\". Using ReuseFactor=2 instead. Valid ReuseFactor(s): 2,3,4,6,8,9,12,16,18,24,32,36,48,64,72,96,144,192,288,576,1152,2304,4608,9216,18432,36864,73728.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Invalid ReuseFactor=1 with \"Resource\" strategy in layer \"conv2d_batchnorm_6\". Using ReuseFactor=2 instead. Valid ReuseFactor(s): 2,3,4,6,8,9,12,16,18,24,32,36,48,64,72,96,128,144,192,288,384,576,1152,2304,4608,9216,18432,36864,73728,147456.\n",
      "WARNING: Invalid ReuseFactor=1 with \"Resource\" strategy in layer \"conv2d_batchnorm_7\". Using ReuseFactor=2 instead. Valid ReuseFactor(s): 2,3,4,6,8,9,12,16,18,24,32,36,48,64,72,96,128,144,192,288,384,576,1152,2304,4608,9216,18432,36864,73728,147456,294912.\n",
      "WARNING: Invalid ReuseFactor=1 with \"Resource\" strategy in layer \"conv2d_batchnorm_8\". Using ReuseFactor=2 instead. Valid ReuseFactor(s): 2,3,4,6,8,9,12,16,18,24,32,36,48,64,72,96,128,144,192,256,288,384,576,768,1152,2304,4608,9216,18432,36864,73728,147456,294912,589824.\n",
      "WARNING: Invalid ReuseFactor=1 with \"Resource\" strategy in layer \"dense\". Using ReuseFactor=2 instead. Valid ReuseFactor(s): 2,3,4,6,8,9,12,16,18,24,32,36,48,64,72,96,128,144,192,256,288,384,576,768,1152,2304,4608,9216,18432,36864,73728,147456,294912,589824.\n",
      "WARNING: Invalid ReuseFactor=1 with \"Resource\" strategy in layer \"dense_1\". Using ReuseFactor=2 instead. Valid ReuseFactor(s): 2,4,8,16,32,64,128,256,512,1024,2048,4096,8192,16384,32768,65536.\n",
      "WARNING: Invalid ReuseFactor=1 with \"Resource\" strategy in layer \"dense_2\". Using ReuseFactor=2 instead. Valid ReuseFactor(s): 2,4,8,16,32,64,128,256.\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import hls4ml\n",
    "import plotting\n",
    "#hls4ml.model.optimizer.OutputRoundingSaturationMode.layers = ['Activation']\n",
    "#hls4ml.model.optimizer.OutputRoundingSaturationMode.rounding_mode = 'AP_RND'\n",
    "hls4ml.model.optimizer.OutputRoundingSaturationMode.saturation_mode = 'AP_SAT'\n",
    "\n",
    "config = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
    "#config['LayerName']['softmax']['exp_table_t'] = 'ap_fixed<18,8>'\n",
    "#config['LayerName']['softmax']['inv_table_t'] = 'ap_fixed<18,4>'\n",
    "config['Model']['Strategy'] = 'Resource'\n",
    "#config['Model']['Precision'] = 'ap_fixed<16,10>'\n",
    "#config['LayerName']['conv2d_batchnorm_8']['Precision']['weight'] = 'ap_fixed<16,4>'\n",
    "#config['LayerName']['conv2d_batchnorm_8']['Precision']['bias'] = 'ap_fixed<16,4>'\n",
    "print(\"-----------------------------------\")\n",
    "plotting.print_dict(config)\n",
    "print(\"-----------------------------------\")\n",
    "hls_model = hls4ml.converters.convert_from_keras_model(model,\n",
    "                                                       hls_config=config,\n",
    "                                                       io_type='io_stream',\n",
    "                                                       output_dir='model_12/hls4ml_myprj',\n",
    "                                                       part=\"xcvu9p-flgb2104-2-i\")\n",
    "                                                       #part='xcu250-figd2104-2L-e')\n",
    "hls_model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "a403c060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score unpruned: 75.88620719909667\n",
      "Score unpruned: 11.490720748901367\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "y_hls = hls_model.predict(x_test_em_barrel[:10])\n",
    "y_unp = model.predict(x_test_em_barrel[:10])\n",
    "print(\"Score hls: {}\".format(mean_absolute_error(y_test_targets[:10], y_hls)))\n",
    "print(\"Score keras: {}\".format(mean_absolute_error(y_test_targets[:10], y_unp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "3291f4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: em_barrel, layer type: InputLayer, input shapes: [[None, 56, 11, 4]], output shape: [None, 56, 11, 4]\n",
      "Layer name: up_sampling, layer type: UpSampling2D, input shapes: [[None, 56, 11, 4]], output shape: [None, 56, 55, 4]\n",
      "Layer name: batch_norm, layer type: BatchNormalization, input shapes: [[None, 56, 55, 4]], output shape: [None, 56, 55, 4]\n",
      "Layer name: conv2d_batchnorm, layer type: QConv2DBatchnorm, input shapes: [[None, 56, 55, 4]], output shape: [None, 56, 55, 16]\n",
      "Layer name: leaky_relu, layer type: LeakyReLU, input shapes: [[None, 56, 55, 16]], output shape: [None, 56, 55, 16]\n",
      "Layer name: max_pooling2D, layer type: MaxPooling2D, input shapes: [[None, 56, 55, 16]], output shape: [None, 28, 27, 16]\n",
      "Layer name: conv2d_batchnorm_1, layer type: QConv2DBatchnorm, input shapes: [[None, 28, 27, 16]], output shape: [None, 28, 27, 32]\n",
      "Layer name: leaky_relu_1, layer type: LeakyReLU, input shapes: [[None, 28, 27, 32]], output shape: [None, 28, 27, 32]\n",
      "Layer name: conv2d_batchnorm_2, layer type: QConv2DBatchnorm, input shapes: [[None, 28, 27, 32]], output shape: [None, 28, 27, 32]\n",
      "Layer name: leaky_relu_2, layer type: LeakyReLU, input shapes: [[None, 28, 27, 32]], output shape: [None, 28, 27, 32]\n",
      "Layer name: max_pooling2D_1, layer type: MaxPooling2D, input shapes: [[None, 28, 27, 32]], output shape: [None, 14, 13, 32]\n",
      "Layer name: conv2d_batchnorm_3, layer type: QConv2DBatchnorm, input shapes: [[None, 14, 13, 32]], output shape: [None, 14, 13, 64]\n",
      "Layer name: leaky_relu_3, layer type: LeakyReLU, input shapes: [[None, 14, 13, 64]], output shape: [None, 14, 13, 64]\n",
      "Layer name: conv2d_batchnorm_4, layer type: QConv2DBatchnorm, input shapes: [[None, 14, 13, 64]], output shape: [None, 14, 13, 64]\n",
      "Layer name: leaky_relu_4, layer type: LeakyReLU, input shapes: [[None, 14, 13, 64]], output shape: [None, 14, 13, 64]\n",
      "Layer name: max_pooling2D_2, layer type: MaxPooling2D, input shapes: [[None, 14, 13, 64]], output shape: [None, 7, 6, 64]\n",
      "Layer name: conv2d_batchnorm_5, layer type: QConv2DBatchnorm, input shapes: [[None, 7, 6, 64]], output shape: [None, 7, 6, 128]\n",
      "Layer name: leaky_relu_5, layer type: LeakyReLU, input shapes: [[None, 7, 6, 128]], output shape: [None, 7, 6, 128]\n",
      "Layer name: conv2d_batchnorm_6, layer type: QConv2DBatchnorm, input shapes: [[None, 7, 6, 128]], output shape: [None, 7, 6, 128]\n",
      "Layer name: leaky_relu_6, layer type: LeakyReLU, input shapes: [[None, 7, 6, 128]], output shape: [None, 7, 6, 128]\n",
      "Layer name: max_pooling2D_3, layer type: MaxPooling2D, input shapes: [[None, 7, 6, 128]], output shape: [None, 3, 3, 128]\n",
      "Layer name: conv2d_batchnorm_7, layer type: QConv2DBatchnorm, input shapes: [[None, 3, 3, 128]], output shape: [None, 3, 3, 256]\n",
      "Layer name: leaky_relu_7, layer type: LeakyReLU, input shapes: [[None, 3, 3, 256]], output shape: [None, 3, 3, 256]\n",
      "Layer name: conv2d_batchnorm_8, layer type: QConv2DBatchnorm, input shapes: [[None, 3, 3, 256]], output shape: [None, 3, 3, 256]\n",
      "Layer name: leaky_relu_8, layer type: LeakyReLU, input shapes: [[None, 3, 3, 256]], output shape: [None, 3, 3, 256]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 3, 3, 256]], output shape: [None, 2304]\n",
      "Layer name: dense, layer type: QDense, input shapes: [[None, 2304]], output shape: [None, 256]\n",
      "Layer name: batch_norm_1, layer type: BatchNormalization, input shapes: [[None, 256]], output shape: [None, 256]\n",
      "Layer name: leaky_relu_9, layer type: LeakyReLU, input shapes: [[None, 256]], output shape: [None, 256]\n",
      "Layer name: dense_1, layer type: QDense, input shapes: [[None, 256]], output shape: [None, 256]\n",
      "Layer name: batch_norm_2, layer type: BatchNormalization, input shapes: [[None, 256]], output shape: [None, 256]\n",
      "Layer name: leaky_relu_10, layer type: LeakyReLU, input shapes: [[None, 256]], output shape: [None, 256]\n",
      "Layer name: dense_2, layer type: QDense, input shapes: [[None, 256]], output shape: [None, 1]\n",
      "Layer name: activate, layer type: Activation, input shapes: [[None, 1]], output shape: [None, 1]\n",
      "Creating HLS model\n",
      "WARNING: Invalid ReuseFactor=1 with \"Resource\" strategy in layer \"conv2d_batchnorm\". Using ReuseFactor=2 instead. Valid ReuseFactor(s): 2,4,5,10,20,25,50,100,200,400,800,1600.\n",
      "WARNING: Invalid ReuseFactor=1 with \"Resource\" strategy in layer \"conv2d_batchnorm_1\". Using ReuseFactor=2 instead. Valid ReuseFactor(s): 2,3,4,6,8,9,12,16,18,24,36,48,72,144,288,576,1152,2304,4608.\n",
      "WARNING: Invalid ReuseFactor=1 with \"Resource\" strategy in layer \"conv2d_batchnorm_2\". Using ReuseFactor=2 instead. Valid ReuseFactor(s): 2,3,4,6,8,9,12,16,18,24,32,36,48,72,96,144,288,576,1152,2304,4608,9216.\n",
      "WARNING: Invalid ReuseFactor=1 with \"Resource\" strategy in layer \"conv2d_batchnorm_3\". Using ReuseFactor=2 instead. Valid ReuseFactor(s): 2,3,4,6,8,9,12,16,18,24,32,36,48,72,96,144,288,576,1152,2304,4608,9216,18432.\n",
      "WARNING: Invalid ReuseFactor=1 with \"Resource\" strategy in layer \"conv2d_batchnorm_4\". Using ReuseFactor=2 instead. Valid ReuseFactor(s): 2,3,4,6,8,9,12,16,18,24,32,36,48,64,72,96,144,192,288,576,1152,2304,4608,9216,18432,36864.\n",
      "WARNING: Invalid ReuseFactor=1 with \"Resource\" strategy in layer \"conv2d_batchnorm_5\". Using ReuseFactor=2 instead. Valid ReuseFactor(s): 2,3,4,6,8,9,12,16,18,24,32,36,48,64,72,96,144,192,288,576,1152,2304,4608,9216,18432,36864,73728.\n",
      "WARNING: Invalid ReuseFactor=1 with \"Resource\" strategy in layer \"conv2d_batchnorm_6\". Using ReuseFactor=2 instead. Valid ReuseFactor(s): 2,3,4,6,8,9,12,16,18,24,32,36,48,64,72,96,128,144,192,288,384,576,1152,2304,4608,9216,18432,36864,73728,147456.\n",
      "WARNING: Invalid ReuseFactor=1 with \"Resource\" strategy in layer \"conv2d_batchnorm_7\". Using ReuseFactor=2 instead. Valid ReuseFactor(s): 2,3,4,6,8,9,12,16,18,24,32,36,48,64,72,96,128,144,192,288,384,576,1152,2304,4608,9216,18432,36864,73728,147456,294912.\n",
      "WARNING: Invalid ReuseFactor=1 with \"Resource\" strategy in layer \"conv2d_batchnorm_8\". Using ReuseFactor=2 instead. Valid ReuseFactor(s): 2,3,4,6,8,9,12,16,18,24,32,36,48,64,72,96,128,144,192,256,288,384,576,768,1152,2304,4608,9216,18432,36864,73728,147456,294912,589824.\n",
      "WARNING: Invalid ReuseFactor=1 with \"Resource\" strategy in layer \"dense\". Using ReuseFactor=2 instead. Valid ReuseFactor(s): 2,3,4,6,8,9,12,16,18,24,32,36,48,64,72,96,128,144,192,256,288,384,576,768,1152,2304,4608,9216,18432,36864,73728,147456,294912,589824.\n",
      "WARNING: Invalid ReuseFactor=1 with \"Resource\" strategy in layer \"dense_1\". Using ReuseFactor=2 instead. Valid ReuseFactor(s): 2,4,8,16,32,64,128,256,512,1024,2048,4096,8192,16384,32768,65536.\n",
      "WARNING: Invalid ReuseFactor=1 with \"Resource\" strategy in layer \"dense_2\". Using ReuseFactor=2 instead. Valid ReuseFactor(s): 2,4,8,16,32,64,128,256.\n",
      "Profiling weights (before optimization)\n",
      "Weights for dense are only zeros, ignoring.\n",
      "Weights for dense_1 are only zeros, ignoring.\n",
      "Profiling weights (final / after optimization)\n",
      "Weights for dense are only zeros, ignoring.\n",
      "Weights for dense_1 are only zeros, ignoring.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<Figure size 432x288 with 1 Axes>,\n",
       " <Figure size 432x288 with 1 Axes>,\n",
       " None,\n",
       " None)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hls4ml.model.profiling.numerical(model=model, hls_model=hls_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "2d04ed91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.        ]\n",
      " [21.46679688]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 5.8671875 ]\n",
      " [22.19042969]\n",
      " [ 0.        ]]\n",
      "[[ 88.281525]\n",
      " [ 87.48941 ]\n",
      " [ 93.36873 ]\n",
      " [ 81.407074]\n",
      " [  0.      ]\n",
      " [ 55.942116]\n",
      " [ 27.957687]\n",
      " [ 92.65228 ]\n",
      " [133.10992 ]\n",
      " [ 56.06463 ]]\n"
     ]
    }
   ],
   "source": [
    "print(y_hls[:100])\n",
    "print(y_unp[:40])\n",
    "#print(y_test_targets[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f39bb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for layer in config['LayerName']:\n",
    "config['LayerName']['activate']['Precision']= 'ap_fixed<18,8>'\n",
    "config['LayerName']['dense_2']['Precision']['weight'] = 'ap_fixed<18,8>'\n",
    "config['LayerName']['dense_2']['Precision']['bias'] = 'ap_fixed<18,8>'\n",
    "config['LayerName']['leaky_relu_10']['Precision'] = 'ap_fixed<18,8>'\n",
    "config['LayerName']['batch_norm_2']['Precision']['scale'] = 'ap_fixed<18,8>'\n",
    "config['LayerName']['batch_norm_2']['Precision']['bias'] = 'ap_fixed<18,8>'\n",
    "config['LayerName']['dense_1']['Precision']['weight'] = 'ap_fixed<18,8>'\n",
    "config['LayerName']['leaky_relu_9']['Precision'] = 'ap_fixed<18,8>'\n",
    "config['LayerName']['batch_norm_1']['Precision']['scale'] = 'ap_fixed<18,8>'\n",
    "config['LayerName']['batch_norm_1']['Precision']['bias'] = 'ap_fixed<18,8>'\n",
    "config['LayerName']['dense']['Precision']['weight'] = 'ap_fixed<18,8>'\n",
    "config['LayerName']['em_barrel']['Precision']['result'] = 'ap_fixed<18,8>'\n",
    "config['LayerName']['up_sampling']['Precision']['result'] = 'ap_fixed<18,8>'\n",
    "config['LayerName']['up_sampling']['Precision']['weight'] = 'ap_fixed<18,8>'\n",
    "config['LayerName']['up_sampling']['Precision']['bias'] = 'ap_fixed<18,8>'\n",
    "config['LayerName']['batch_norm']['Precision']['scale'] = 'ap_fixed<18,8>'\n",
    "config['LayerName']['batch_norm']['Precision']['bias'] = 'ap_fixed<18,8>'\n",
    "config['LayerName']['conv2d_batchnorm']['Precision']['weight'] = 'ap_fixed<18,8>'\n",
    "config['LayerName']['conv2d_batchnorm']['Precision']['bias'] = 'ap_fixed<18,8>'\n",
    "config['LayerName']['leaky_relu']['Precision'] = 'ap_fixed<18,8>'\n",
    "config['LayerName']['max_pooling2D']['Precision'] = 'ap_fixed<18,8>'\n",
    "\n",
    "config['LayerName']['conv2d_batchnorm_1']['Precision']['weight'] = 'ap_fixed<18,8>'\n",
    "config['LayerName']['conv2d_batchnorm_1']['Precision']['bias'] = 'ap_fixed<18,8>'\n",
    "config['LayerName']['leaky_relu_1']['Precision'] = 'ap_fixed<18,8>'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c9cdd2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "em_barrel\n",
      "{'Precision': {'result': 'ap_fixed<16,6>'}}\n",
      "up_sampling\n",
      "{'Precision': {'weight': 'ap_fixed<16,6>', 'bias': 'ap_fixed<16,6>', 'result': 'ap_fixed<16,6>'}, 'ReuseFactor': 1}\n",
      "batch_norm\n",
      "{'Precision': {'scale': 'ap_fixed<16,6>', 'bias': 'ap_fixed<16,6>'}, 'ReuseFactor': 1}\n",
      "conv2d_batchnorm\n",
      "{'Precision': {'weight': 'ap_fixed<16,11>', 'bias': 'ap_fixed<16,11>'}, 'ReuseFactor': 1}\n",
      "leaky_relu\n",
      "{'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>'}\n",
      "max_pooling2D\n",
      "{'Precision': 'ap_fixed<16,6>'}\n",
      "conv2d_batchnorm_1\n",
      "{'Precision': {'weight': 'ap_fixed<16,11>', 'bias': 'ap_fixed<16,11>'}, 'ReuseFactor': 1}\n",
      "leaky_relu_1\n",
      "{'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>'}\n",
      "conv2d_batchnorm_2\n",
      "{'Precision': {'weight': 'ap_fixed<16,11>', 'bias': 'ap_fixed<16,11>'}, 'ReuseFactor': 1}\n",
      "leaky_relu_2\n",
      "{'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>'}\n",
      "max_pooling2D_1\n",
      "{'Precision': 'ap_fixed<16,6>'}\n",
      "conv2d_batchnorm_3\n",
      "{'Precision': {'weight': 'ap_fixed<16,11>', 'bias': 'ap_fixed<16,11>'}, 'ReuseFactor': 1}\n",
      "leaky_relu_3\n",
      "{'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>'}\n",
      "conv2d_batchnorm_4\n",
      "{'Precision': {'weight': 'ap_fixed<16,11>', 'bias': 'ap_fixed<16,11>'}, 'ReuseFactor': 1}\n",
      "leaky_relu_4\n",
      "{'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>'}\n",
      "max_pooling2D_2\n",
      "{'Precision': 'ap_fixed<16,6>'}\n",
      "conv2d_batchnorm_5\n",
      "{'Precision': {'weight': 'ap_fixed<16,11>', 'bias': 'ap_fixed<16,11>'}, 'ReuseFactor': 1}\n",
      "leaky_relu_5\n",
      "{'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>'}\n",
      "conv2d_batchnorm_6\n",
      "{'Precision': {'weight': 'ap_fixed<16,11>', 'bias': 'ap_fixed<16,11>'}, 'ReuseFactor': 1}\n",
      "leaky_relu_6\n",
      "{'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>'}\n",
      "max_pooling2D_3\n",
      "{'Precision': 'ap_fixed<16,6>'}\n",
      "conv2d_batchnorm_7\n",
      "{'Precision': {'weight': 'ap_fixed<16,11>', 'bias': 'ap_fixed<16,11>'}, 'ReuseFactor': 1}\n",
      "leaky_relu_7\n",
      "{'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>'}\n",
      "conv2d_batchnorm_8\n",
      "{'Precision': {'weight': 'ap_fixed<16,11>', 'bias': 'ap_fixed<16,11>'}, 'ReuseFactor': 1}\n",
      "leaky_relu_8\n",
      "{'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>'}\n",
      "dense\n",
      "{'Precision': {'weight': 'ap_fixed<16,11>'}, 'ReuseFactor': 1}\n",
      "batch_norm_1\n",
      "{'Precision': {'scale': 'ap_fixed<16,6>', 'bias': 'ap_fixed<16,6>'}, 'ReuseFactor': 1}\n",
      "leaky_relu_9\n",
      "{'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>'}\n",
      "dense_1\n",
      "{'Precision': {'weight': 'ap_fixed<16,11>'}, 'ReuseFactor': 1}\n",
      "batch_norm_2\n",
      "{'Precision': {'scale': 'ap_fixed<16,6>', 'bias': 'ap_fixed<16,6>'}, 'ReuseFactor': 1}\n",
      "leaky_relu_10\n",
      "{'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>'}\n",
      "dense_2\n",
      "{'Precision': {'weight': 'ap_fixed<16,11>', 'bias': 'ap_fixed<16,11>'}, 'ReuseFactor': 1}\n",
      "activate\n",
      "{'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>'}\n"
     ]
    }
   ],
   "source": [
    "for layer in config['LayerName']:\n",
    "    print(layer)\n",
    "    print(config['LayerName'][layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e82d9e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
